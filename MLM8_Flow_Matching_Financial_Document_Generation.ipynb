{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RDGopal/IB9AU-2026/blob/main/MLM8_Flow_Matching_Financial_Document_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#From Standard Diffusion to \"Conditional Flow Matching\" (CFM).\n",
        "\n",
        "WHY?\n",
        "1. Speed: CFM allows us to generate images in 10-50 steps (vs 500-1000 for Diffusion).\n",
        "2. Stability: It learns straight-line paths from Noise -> Data (Optimal Transport).\n",
        "3. Applications: Excellent for structural data like Floor Plans (CubiCasa5k)\n",
        "   or Financial Docs where geometry matters.\n",
        "\n",
        "GOAL:\n",
        "Train a Flow Matching Model to transport random noise into structured documents.\n",
        "\n"
      ],
      "metadata": {
        "id": "WXm9lhNjU7d1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.utils import make_grid\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import os\n",
        "from PIL import Image, ImageDraw\n"
      ],
      "metadata": {
        "id": "y9VNCqUsVCNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 2. INTERNAL UTILITIES (Data Generator)\n",
        "# ==========================================\n",
        "# We define the generator here so the notebook is self-contained.\n",
        "\n",
        "def create_financial_document(doc_type=None, size=(64, 64)):\n",
        "    \"\"\"Generates a low-res synthetic financial document.\"\"\"\n",
        "    w, h = size\n",
        "    img = Image.new('L', size, color=255) # White background\n",
        "    draw = ImageDraw.Draw(img)\n",
        "\n",
        "    if doc_type is None:\n",
        "        doc_type = random.choice(['invoice', 'receipt', 'chart'])\n",
        "\n",
        "    if doc_type == 'invoice':\n",
        "        # Header block\n",
        "        draw.rectangle([2, 2, w//3, 10], fill=200) # Logo\n",
        "        draw.rectangle([w//3 + 4, 4, w-5, 8], fill=0) # Title\n",
        "        # Grid Lines\n",
        "        margin = 5\n",
        "        line_height = (h - 20) // 5\n",
        "        start_y = 15\n",
        "        for i in range(5):\n",
        "            y = start_y + i * line_height\n",
        "            draw.line([margin, y, w-margin, y], fill=180, width=1)\n",
        "            draw.rectangle([margin, y+2, margin+10, y+line_height-2], fill=100) # Item\n",
        "            draw.rectangle([w-20, y+2, w-margin, y+line_height-2], fill=100) # Price\n",
        "        # Total\n",
        "        draw.rectangle([w-25, h-10, w-5, h-4], fill=0)\n",
        "\n",
        "    elif doc_type == 'receipt':\n",
        "        # Narrower content, centered\n",
        "        margin = w // 4\n",
        "        # Shop Header\n",
        "        draw.rectangle([margin, 2, w-margin, 8], fill=0)\n",
        "        # List of items\n",
        "        for y in range(12, h-15, 4):\n",
        "            draw.line([margin, y, margin + 10, y], fill=50, width=1) # Item\n",
        "            draw.line([w-margin-10, y, w-margin, y], fill=50, width=1) # Price\n",
        "        # Divider & Total\n",
        "        draw.line([margin, h-12, w-margin, h-12], fill=0, width=1)\n",
        "        draw.rectangle([margin+5, h-10, w-margin-5, h-4], fill=0)\n",
        "\n",
        "    elif doc_type == 'chart':\n",
        "        # Axes\n",
        "        draw.line([5, 5, 5, h-5], fill=0, width=1)\n",
        "        draw.line([5, h-5, w-5, h-5], fill=0, width=1)\n",
        "        # Random Bar or Line\n",
        "        if random.random() > 0.5:\n",
        "            bar_w = (w - 10) // 6\n",
        "            for i in range(5):\n",
        "                height = random.randint(5, h-10)\n",
        "                x = 10 + i * bar_w\n",
        "                draw.rectangle([x, h-5-height, x+bar_w-2, h-5], fill=150)\n",
        "        else:\n",
        "            points = []\n",
        "            for i in range(6):\n",
        "                x = 5 + i * ((w-10)//5)\n",
        "                y = h - 5 - random.randint(5, h-15)\n",
        "                points.append((x, y))\n",
        "            draw.line(points, fill=0, width=2)\n",
        "    return img\n",
        "\n",
        "class FinancialDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, num_samples=1000, size=(64, 64), transform=None):\n",
        "        self.num_samples = num_samples\n",
        "        self.size = size\n",
        "        self.transform = transform\n",
        "        self.data = []\n",
        "        self.labels = []\n",
        "\n",
        "        # Pre-generate data\n",
        "        print(f\"Synthesizing {num_samples} documents...\")\n",
        "        for _ in range(num_samples):\n",
        "            label_str = random.choice(['invoice', 'receipt', 'chart'])\n",
        "            img = create_financial_document(label_str, size)\n",
        "            label_map = {'invoice': 0, 'receipt': 1, 'chart': 2}\n",
        "            self.data.append(img)\n",
        "            self.labels.append(label_map[label_str])\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.data[idx]\n",
        "        label = self.labels[idx]\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, label\n"
      ],
      "metadata": {
        "id": "7gNrUfRQVHJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 3. CONFIGURATION & MODEL\n",
        "# ==========================================\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "HPARAMS = {\n",
        "    \"img_size\": 64,\n",
        "    \"inference_steps\": 50,  # MUCH lower than diffusion (usually 500+)\n",
        "    \"batch_size\": 32,\n",
        "    \"lr\": 1e-4,             # Flow matching often likes slightly smaller LR\n",
        "    \"epochs\": 15,\n",
        "    \"channels\": 1,\n",
        "    \"num_classes\": 3\n",
        "}\n",
        "\n",
        "class SinusoidalPositionEmbeddings(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "    def forward(self, time):\n",
        "        # time in flow matching is 0 to 1 float, not integer steps\n",
        "        device = time.device\n",
        "        half_dim = self.dim // 2\n",
        "        embeddings = np.log(10000) / (half_dim - 1)\n",
        "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
        "        embeddings = time[:, None] * embeddings[None, :]\n",
        "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
        "        return embeddings\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, time_emb_dim, up=False):\n",
        "        super().__init__()\n",
        "        self.time_mlp = nn.Linear(time_emb_dim, out_ch)\n",
        "        if up:\n",
        "            self.conv1 = nn.Conv2d(2*in_ch, out_ch, 3, padding=1)\n",
        "            self.transform = nn.ConvTranspose2d(out_ch, out_ch, 4, 2, 1)\n",
        "        else:\n",
        "            self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding=1)\n",
        "            self.transform = nn.Conv2d(out_ch, out_ch, 4, 2, 1)\n",
        "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1)\n",
        "        self.bnorm1 = nn.BatchNorm2d(out_ch)\n",
        "        self.bnorm2 = nn.BatchNorm2d(out_ch)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        h = self.bnorm1(self.relu(self.conv1(x)))\n",
        "        time_emb = self.relu(self.time_mlp(t))\n",
        "        time_emb = time_emb[(..., ) + (None, ) * 2]\n",
        "        h = h + time_emb\n",
        "        h = self.bnorm2(self.relu(self.conv2(h)))\n",
        "        return self.transform(h)\n",
        "\n",
        "class ConditionalUNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        img_channels = HPARAMS[\"channels\"]\n",
        "        down_channels = (32, 64, 128)\n",
        "        up_channels = (128, 64, 32)\n",
        "        out_dim = img_channels\n",
        "        time_emb_dim = 32\n",
        "        classes = HPARAMS[\"num_classes\"]\n",
        "\n",
        "        self.time_mlp = nn.Sequential(\n",
        "            SinusoidalPositionEmbeddings(time_emb_dim),\n",
        "            nn.Linear(time_emb_dim, time_emb_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.class_emb = nn.Embedding(classes, time_emb_dim)\n",
        "        self.conv0 = nn.Conv2d(img_channels, down_channels[0], 3, padding=1)\n",
        "        self.downs = nn.ModuleList([Block(down_channels[i], down_channels[i+1], time_emb_dim) for i in range(len(down_channels)-1)])\n",
        "        self.ups = nn.ModuleList([Block(up_channels[i], up_channels[i+1], time_emb_dim, up=True) for i in range(len(up_channels)-1)])\n",
        "        self.output = nn.Conv2d(up_channels[-1], out_dim, 1)\n",
        "\n",
        "    def forward(self, x, t_float, class_label):\n",
        "        # x: input image (noisy or clean)\n",
        "        # t_float: float between 0 and 1\n",
        "        t = self.time_mlp(t_float)\n",
        "        c = self.class_emb(class_label)\n",
        "        t = t + c\n",
        "        x = self.conv0(x)\n",
        "        residuals = []\n",
        "        for down in self.downs:\n",
        "            x = down(x, t)\n",
        "            residuals.append(x)\n",
        "        for up in self.ups:\n",
        "            residual = residuals.pop()\n",
        "            x = torch.cat((x, residual), dim=1)\n",
        "            x = up(x, t)\n",
        "        return self.output(x)\n"
      ],
      "metadata": {
        "id": "EFnq7umuVR6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 4. FLOW MATCHING LOGIC\n",
        "# ==========================================\n",
        "\n",
        "class FlowMatching:\n",
        "    def __init__(self):\n",
        "        # No betas/alphas needed! Just linear interpolation.\n",
        "        pass\n",
        "\n",
        "    def compute_loss(self, model, x_1, labels):\n",
        "        \"\"\"\n",
        "        x_1: Real data samples (Batch, C, H, W)\n",
        "        \"\"\"\n",
        "        b = x_1.shape[0]\n",
        "        # 1. Sample Noise (x_0)\n",
        "        x_0 = torch.randn_like(x_1)\n",
        "\n",
        "        # 2. Sample time t uniform [0, 1]\n",
        "        t = torch.rand(b, device=x_1.device)\n",
        "\n",
        "        # 3. Compute linear interpolation (Optimal Transport path)\n",
        "        # x_t = (1 - t) * x_0 + t * x_1\n",
        "        # Reshape t for broadcasting\n",
        "        t_view = t.view(b, 1, 1, 1)\n",
        "        x_t = (1 - t_view) * x_0 + t_view * x_1\n",
        "\n",
        "        # 4. Target Velocity (v_t)\n",
        "        # The vector that points from Noise (x_0) to Data (x_1)\n",
        "        v_target = x_1 - x_0\n",
        "\n",
        "        # 5. Predict Velocity\n",
        "        v_pred = model(x_t, t, labels)\n",
        "\n",
        "        # 6. MSE Loss\n",
        "        return F.mse_loss(v_pred, v_target)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def sample(self, model, n_samples, class_label_idx, size, steps=50):\n",
        "        \"\"\"\n",
        "        Euler ODE Solver to move from Noise (t=0) to Data (t=1)\n",
        "        \"\"\"\n",
        "        model.eval()\n",
        "        # Start at pure noise (t=0)\n",
        "        x = torch.randn((n_samples, 1, size, size)).to(device)\n",
        "        labels = torch.full((n_samples,), class_label_idx, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step size\n",
        "        dt = 1.0 / steps\n",
        "\n",
        "        # Integrate from 0 to 1\n",
        "        for i in range(steps):\n",
        "            t_curr = torch.ones(n_samples).to(device) * (i / steps)\n",
        "\n",
        "            # Predict velocity at current point\n",
        "            v_pred = model(x, t_curr, labels)\n",
        "\n",
        "            # Euler Step: x_new = x_old + velocity * dt\n",
        "            x = x + v_pred * dt\n",
        "\n",
        "        model.train()\n",
        "        return x\n",
        "\n",
        "def train():\n",
        "    # 1. Prepare Data\n",
        "    dataset = FinancialDataset(num_samples=2000, size=(HPARAMS[\"img_size\"], HPARAMS[\"img_size\"]), transform=transforms.ToTensor())\n",
        "    dataloader = DataLoader(dataset, batch_size=HPARAMS[\"batch_size\"], shuffle=True)\n",
        "\n",
        "    # 2. Initialize\n",
        "    model = ConditionalUNet().to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=HPARAMS[\"lr\"])\n",
        "    flow = FlowMatching() # Use Flow Matching manager\n",
        "\n",
        "    print(f\"Starting Flow Matching training for {HPARAMS['epochs']} epochs...\")\n",
        "    for epoch in range(HPARAMS['epochs']):\n",
        "        pbar = tqdm(dataloader)\n",
        "        epoch_loss = 0\n",
        "        for step, (images, labels) in enumerate(pbar):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Compute Flow Matching Loss\n",
        "            loss = flow.compute_loss(model, images, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            pbar.set_description(f\"Epoch {epoch} | Loss: {loss.item():.4f}\")\n",
        "\n",
        "    return model, flow"
      ],
      "metadata": {
        "id": "tKul52YGVY8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 5. SAVE & LOAD UTILITIES\n",
        "# ==========================================\n",
        "\n",
        "def save_model(model, filename=\"fintech_flow_model.pth\"):\n",
        "    \"\"\"Saves model weights to disk.\"\"\"\n",
        "    torch.save(model.state_dict(), filename)\n",
        "    print(f\"‚úÖ Model saved to {filename}\")\n",
        "\n",
        "def load_model(filename=\"fintech_flow_model.pth\"):\n",
        "    \"\"\"Creates a new model instance and loads weights.\"\"\"\n",
        "    if not os.path.exists(filename):\n",
        "        print(f\"‚ùå Error: {filename} not found.\")\n",
        "        return None\n",
        "\n",
        "    model = ConditionalUNet().to(device)\n",
        "    model.load_state_dict(torch.load(filename, map_location=device))\n",
        "    model.eval()\n",
        "    print(f\"‚úÖ Model loaded from {filename}\")\n",
        "    return model\n",
        "\n",
        "def generate_single_document(model, flow, doc_type='invoice'):\n",
        "    \"\"\"Generates a single image of the requested type.\"\"\"\n",
        "    label_map = {'invoice': 0, 'receipt': 1, 'chart': 2}\n",
        "\n",
        "    if doc_type not in label_map:\n",
        "        print(f\"‚ùå Unknown type: {doc_type}. Use 'invoice', 'receipt', or 'chart'\")\n",
        "        return\n",
        "\n",
        "    print(f\"üé® Generating new {doc_type} with ODE Solver...\")\n",
        "    sample_tensor = flow.sample(model, n_samples=1, class_label_idx=label_map[doc_type],\n",
        "                                size=HPARAMS[\"img_size\"], steps=HPARAMS[\"inference_steps\"])\n",
        "\n",
        "    # Convert tensor to displayable image\n",
        "    img = sample_tensor[0].cpu().permute(1, 2, 0).numpy()\n",
        "    img = (img - img.min()) / (img.max() - img.min()) # Normalize to 0-1\n",
        "\n",
        "    plt.figure(figsize=(4,4))\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    plt.title(f\"Generated {doc_type.capitalize()}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "def visualize_results(model, flow):\n",
        "    print(\"\\nGenerating Grid of Samples (Euler Step)...\")\n",
        "    steps = HPARAMS[\"inference_steps\"]\n",
        "    invoices = flow.sample(model, 4, 0, HPARAMS[\"img_size\"], steps=steps)\n",
        "    receipts = flow.sample(model, 4, 1, HPARAMS[\"img_size\"], steps=steps)\n",
        "    charts = flow.sample(model, 4, 2, HPARAMS[\"img_size\"], steps=steps)\n",
        "\n",
        "    all_images = torch.cat([invoices, receipts, charts], dim=0)\n",
        "    grid = make_grid(all_images, nrow=4, padding=2, normalize=True)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.imshow(grid.permute(1, 2, 0).cpu().numpy(), cmap='gray')\n",
        "    plt.title(\"Generated: Invoices (Top), Receipts (Mid), Charts (Bot)\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 1. Train the Flow Matching model\n",
        "    trained_model, flow_manager = train()\n",
        "\n",
        "    # 2. Save\n",
        "    save_model(trained_model, \"fintech_flow_model.pth\")\n",
        "\n",
        "    # 3. Visualize\n",
        "    visualize_results(trained_model, flow_manager)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "JNmyVzQzSA7L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load and Run the Saved Model to Generate Financial Documents"
      ],
      "metadata": {
        "id": "SvBExwFgFH_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.utils import make_grid\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import os\n",
        "from PIL import Image, ImageDraw\n"
      ],
      "metadata": {
        "id": "6CUTzTpSDhBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0bf9b53"
      },
      "source": [
        "loaded_model = load_model(\"fintech_flow_model.pth\")\n",
        "flow_manager_instance = FlowMatching() # Re-instantiate the FlowMatching class\n",
        "\n",
        "if loaded_model:\n",
        "    # Generate an invoice\n",
        "    generate_single_document(loaded_model, flow_manager_instance, doc_type='invoice')\n",
        "\n",
        "    # Generate a receipt\n",
        "    generate_single_document(loaded_model, flow_manager_instance, doc_type='receipt')\n",
        "\n",
        "    # Generate a chart\n",
        "    generate_single_document(loaded_model, flow_manager_instance, doc_type='chart')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
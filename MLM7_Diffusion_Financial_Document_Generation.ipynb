{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RDGopal/IB9AU-2026/blob/main/MLM7_Diffusion_Financial_Document_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Financial Document Generation with Diffusion\n",
        "\n",
        "CONTEXT: PRIVACY-PRESERVING SYNTHETIC DATA\n",
        "In FinTech, we often cannot train OCR (Optical Character Recognition) models\n",
        "on real client invoices due to GDPR/PII regulations.\n",
        "\n",
        "SOLUTION:\n",
        "We train a Diffusion model on the *structure* of invoices (layout, lines, headers)\n",
        "but without real text. We then use these 'hallucinated' documents to pre-train\n",
        "OCR systems or stress-test fraud detection pipelines.\n",
        "\n",
        "GOAL:\n",
        "Train a Conditional Diffusion Model that can generate:\n",
        "- Class 0: Invoices (Grid structure)\n",
        "- Class 1: Receipts (List structure)\n",
        "- Class 2: Charts (Visual structure)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "p9MxQ0hyCp6S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.utils import make_grid\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "from PIL import Image, ImageDraw"
      ],
      "metadata": {
        "id": "95N_OBYHCv8Q"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 2. INTERNAL UTILITIES (Data Generator)\n",
        "# ==========================================\n",
        "# We define the generator here so the notebook is self-contained.\n",
        "\n",
        "def create_financial_document(doc_type=None, size=(64, 64)):\n",
        "    \"\"\"Generates a low-res synthetic financial document.\"\"\"\n",
        "    w, h = size\n",
        "    img = Image.new('L', size, color=255) # White background\n",
        "    draw = ImageDraw.Draw(img)\n",
        "\n",
        "    if doc_type is None:\n",
        "        doc_type = random.choice(['invoice', 'receipt', 'chart'])\n",
        "\n",
        "    if doc_type == 'invoice':\n",
        "        # Header block\n",
        "        draw.rectangle([2, 2, w//3, 10], fill=200) # Logo\n",
        "        draw.rectangle([w//3 + 4, 4, w-5, 8], fill=0) # Title\n",
        "        # Grid Lines\n",
        "        margin = 5\n",
        "        line_height = (h - 20) // 5\n",
        "        start_y = 15\n",
        "        for i in range(5):\n",
        "            y = start_y + i * line_height\n",
        "            draw.line([margin, y, w-margin, y], fill=180, width=1)\n",
        "            draw.rectangle([margin, y+2, margin+10, y+line_height-2], fill=100) # Item\n",
        "            draw.rectangle([w-20, y+2, w-margin, y+line_height-2], fill=100) # Price\n",
        "        # Total\n",
        "        draw.rectangle([w-25, h-10, w-5, h-4], fill=0)\n",
        "\n",
        "    elif doc_type == 'receipt':\n",
        "        # Narrower content, centered\n",
        "        margin = w // 4\n",
        "        # Shop Header\n",
        "        draw.rectangle([margin, 2, w-margin, 8], fill=0)\n",
        "        # List of items\n",
        "        for y in range(12, h-15, 4):\n",
        "            draw.line([margin, y, margin + 10, y], fill=50, width=1) # Item\n",
        "            draw.line([w-margin-10, y, w-margin, y], fill=50, width=1) # Price\n",
        "        # Divider & Total\n",
        "        draw.line([margin, h-12, w-margin, h-12], fill=0, width=1)\n",
        "        draw.rectangle([margin+5, h-10, w-margin-5, h-4], fill=0)\n",
        "\n",
        "    elif doc_type == 'chart':\n",
        "        # Axes\n",
        "        draw.line([5, 5, 5, h-5], fill=0, width=1)\n",
        "        draw.line([5, h-5, w-5, h-5], fill=0, width=1)\n",
        "        # Random Bar or Line\n",
        "        if random.random() > 0.5:\n",
        "            bar_w = (w - 10) // 6\n",
        "            for i in range(5):\n",
        "                height = random.randint(5, h-10)\n",
        "                x = 10 + i * bar_w\n",
        "                draw.rectangle([x, h-5-height, x+bar_w-2, h-5], fill=150)\n",
        "        else:\n",
        "            points = []\n",
        "            for i in range(6):\n",
        "                x = 5 + i * ((w-10)//5)\n",
        "                y = h - 5 - random.randint(5, h-15)\n",
        "                points.append((x, y))\n",
        "            draw.line(points, fill=0, width=2)\n",
        "    return img\n",
        "\n",
        "class FinancialDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, num_samples=1000, size=(64, 64), transform=None):\n",
        "        self.num_samples = num_samples\n",
        "        self.size = size\n",
        "        self.transform = transform\n",
        "        self.data = []\n",
        "        self.labels = []\n",
        "\n",
        "        # Pre-generate data\n",
        "        print(f\"Synthesizing {num_samples} documents...\")\n",
        "        for _ in range(num_samples):\n",
        "            label_str = random.choice(['invoice', 'receipt', 'chart'])\n",
        "            img = create_financial_document(label_str, size)\n",
        "            label_map = {'invoice': 0, 'receipt': 1, 'chart': 2}\n",
        "            self.data.append(img)\n",
        "            self.labels.append(label_map[label_str])\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.data[idx]\n",
        "        label = self.labels[idx]\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, label\n"
      ],
      "metadata": {
        "id": "BK97YD-XDFwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 3. CONFIGURATION & MODEL\n",
        "# ==========================================\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "HPARAMS = {\n",
        "    \"img_size\": 64,\n",
        "    \"timesteps\": 500,\n",
        "    \"batch_size\": 32,\n",
        "    \"lr\": 3e-4,\n",
        "    \"epochs\": 10,\n",
        "    \"channels\": 1,\n",
        "    \"num_classes\": 3\n",
        "}\n",
        "\n",
        "class SinusoidalPositionEmbeddings(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "    def forward(self, time):\n",
        "        device = time.device\n",
        "        half_dim = self.dim // 2\n",
        "        embeddings = np.log(10000) / (half_dim - 1)\n",
        "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
        "        embeddings = time[:, None] * embeddings[None, :]\n",
        "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
        "        return embeddings\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, time_emb_dim, up=False):\n",
        "        super().__init__()\n",
        "        self.time_mlp = nn.Linear(time_emb_dim, out_ch)\n",
        "        if up:\n",
        "            self.conv1 = nn.Conv2d(2*in_ch, out_ch, 3, padding=1)\n",
        "            self.transform = nn.ConvTranspose2d(out_ch, out_ch, 4, 2, 1)\n",
        "        else:\n",
        "            self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding=1)\n",
        "            self.transform = nn.Conv2d(out_ch, out_ch, 4, 2, 1)\n",
        "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1)\n",
        "        self.bnorm1 = nn.BatchNorm2d(out_ch)\n",
        "        self.bnorm2 = nn.BatchNorm2d(out_ch)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        h = self.bnorm1(self.relu(self.conv1(x)))\n",
        "        time_emb = self.relu(self.time_mlp(t))\n",
        "        time_emb = time_emb[(..., ) + (None, ) * 2]\n",
        "        h = h + time_emb\n",
        "        h = self.bnorm2(self.relu(self.conv2(h)))\n",
        "        return self.transform(h)\n",
        "\n",
        "class ConditionalUNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        img_channels = HPARAMS[\"channels\"]\n",
        "        down_channels = (32, 64, 128)\n",
        "        up_channels = (128, 64, 32)\n",
        "        out_dim = img_channels\n",
        "        time_emb_dim = 32\n",
        "        classes = HPARAMS[\"num_classes\"]\n",
        "\n",
        "        self.time_mlp = nn.Sequential(\n",
        "            SinusoidalPositionEmbeddings(time_emb_dim),\n",
        "            nn.Linear(time_emb_dim, time_emb_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.class_emb = nn.Embedding(classes, time_emb_dim)\n",
        "        self.conv0 = nn.Conv2d(img_channels, down_channels[0], 3, padding=1)\n",
        "        self.downs = nn.ModuleList([Block(down_channels[i], down_channels[i+1], time_emb_dim) for i in range(len(down_channels)-1)])\n",
        "        self.ups = nn.ModuleList([Block(up_channels[i], up_channels[i+1], time_emb_dim, up=True) for i in range(len(up_channels)-1)])\n",
        "        self.output = nn.Conv2d(up_channels[-1], out_dim, 1)\n",
        "\n",
        "    def forward(self, x, timestep, class_label):\n",
        "        t = self.time_mlp(timestep)\n",
        "        c = self.class_emb(class_label)\n",
        "        t = t + c\n",
        "        x = self.conv0(x)\n",
        "        residuals = []\n",
        "        for down in self.downs:\n",
        "            x = down(x, t)\n",
        "            residuals.append(x)\n",
        "        for up in self.ups:\n",
        "            residual = residuals.pop()\n",
        "            x = torch.cat((x, residual), dim=1)\n",
        "            x = up(x, t)\n",
        "        return self.output(x)\n"
      ],
      "metadata": {
        "id": "KlNnmml_DUhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 4. TRAINING & SAMPLING\n",
        "# ==========================================\n",
        "class DiffusionManager:\n",
        "    def __init__(self, timesteps=500, start=0.0001, end=0.02):\n",
        "        self.timesteps = timesteps\n",
        "        self.betas = torch.linspace(start, end, timesteps).to(device)\n",
        "        self.alphas = 1. - self.betas\n",
        "        self.alphas_cumprod = torch.cumprod(self.alphas, axis=0)\n",
        "        self.sqrt_alphas_cumprod = torch.sqrt(self.alphas_cumprod)\n",
        "        self.sqrt_one_minus_alphas_cumprod = torch.sqrt(1. - self.alphas_cumprod)\n",
        "\n",
        "    def forward_noise(self, x_0, t):\n",
        "        noise = torch.randn_like(x_0)\n",
        "        sqrt_alpha_bar_t = self.sqrt_alphas_cumprod[t][:, None, None, None]\n",
        "        sqrt_one_minus_alpha_bar_t = self.sqrt_one_minus_alphas_cumprod[t][:, None, None, None]\n",
        "        return sqrt_alpha_bar_t * x_0 + sqrt_one_minus_alpha_bar_t * noise, noise\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def sample(self, model, n_samples, class_label_idx, size):\n",
        "        model.eval()\n",
        "        x = torch.randn((n_samples, 1, size, size)).to(device)\n",
        "        labels = torch.full((n_samples,), class_label_idx, dtype=torch.long).to(device)\n",
        "        for i in reversed(range(1, self.timesteps)):\n",
        "            t = (torch.ones(n_samples) * i).long().to(device)\n",
        "            predicted_noise = model(x, t, labels)\n",
        "            alpha = self.alphas[t][:, None, None, None]\n",
        "            alpha_hat = self.alphas_cumprod[t][:, None, None, None]\n",
        "            beta = self.betas[t][:, None, None, None]\n",
        "            if i > 1:\n",
        "                noise = torch.randn_like(x)\n",
        "            else:\n",
        "                noise = torch.zeros_like(x)\n",
        "            x = (1 / torch.sqrt(alpha)) * (x - ((1 - alpha) / (torch.sqrt(1 - alpha_hat))) * predicted_noise) + torch.sqrt(beta) * noise\n",
        "        model.train()\n",
        "        return x\n",
        "\n",
        "def train():\n",
        "    # 1. Prepare Data\n",
        "    dataset = FinancialDataset(num_samples=2000, size=(HPARAMS[\"img_size\"], HPARAMS[\"img_size\"]), transform=transforms.ToTensor())\n",
        "    dataloader = DataLoader(dataset, batch_size=HPARAMS[\"batch_size\"], shuffle=True)\n",
        "\n",
        "    # 2. Initialize\n",
        "    model = ConditionalUNet().to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=HPARAMS[\"lr\"])\n",
        "    diffusion = DiffusionManager(timesteps=HPARAMS[\"timesteps\"])\n",
        "    loss_fn = nn.MSELoss()\n",
        "\n",
        "    print(f\"Starting training for {HPARAMS['epochs']} epochs...\")\n",
        "    for epoch in range(HPARAMS['epochs']):\n",
        "        pbar = tqdm(dataloader)\n",
        "        epoch_loss = 0\n",
        "        for step, (images, labels) in enumerate(pbar):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            t = torch.randint(0, HPARAMS[\"timesteps\"], (images.shape[0],), device=device).long()\n",
        "            x_noisy, noise = diffusion.forward_noise(images, t)\n",
        "            noise_pred = model(x_noisy, t, labels)\n",
        "            loss = loss_fn(noise_pred, noise)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "            pbar.set_description(f\"Epoch {epoch} | Loss: {loss.item():.4f}\")\n",
        "    return model, diffusion\n",
        "\n",
        "def visualize_results(model, diffusion):\n",
        "    print(\"\\nGenerating Class 0 (Invoices)...\")\n",
        "    invoices = diffusion.sample(model, 4, 0, HPARAMS[\"img_size\"])\n",
        "    print(\"Generating Class 1 (Receipts)...\")\n",
        "    receipts = diffusion.sample(model, 4, 1, HPARAMS[\"img_size\"])\n",
        "    print(\"Generating Class 2 (Charts)...\")\n",
        "    charts = diffusion.sample(model, 4, 2, HPARAMS[\"img_size\"])\n",
        "\n",
        "    all_images = torch.cat([invoices, receipts, charts], dim=0)\n",
        "    grid = make_grid(all_images, nrow=4, padding=2, normalize=True)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.imshow(grid.permute(1, 2, 0).cpu().numpy(), cmap='gray')\n",
        "    plt.title(\"Generated: Invoices (Top), Receipts (Mid), Charts (Bot)\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    trained_model, diff_manager = train()\n",
        "    visualize_results(trained_model, diff_manager)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "BVsgcf64Cm9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 5. SAVE & LOAD UTILITIES (NEW)\n",
        "# ==========================================\n",
        "\n",
        "def save_model(model, filename=\"fintech_diffusion_model.pth\"):\n",
        "    \"\"\"Saves model weights to disk.\"\"\"\n",
        "    torch.save(model.state_dict(), filename)\n",
        "    print(f\"‚úÖ Model saved to {filename}\")\n",
        "\n",
        "def load_model(filename=\"fintech_diffusion_model.pth\"):\n",
        "    \"\"\"Creates a new model instance and loads weights.\"\"\"\n",
        "    if not os.path.exists(filename):\n",
        "        print(f\"‚ùå Error: {filename} not found.\")\n",
        "        return None\n",
        "\n",
        "    model = ConditionalUNet().to(device)\n",
        "    model.load_state_dict(torch.load(filename, map_location=device))\n",
        "    model.eval()\n",
        "    print(f\"‚úÖ Model loaded from {filename}\")\n",
        "    return model\n",
        "\n",
        "def generate_single_document(model, diffusion, doc_type='invoice'):\n",
        "    \"\"\"Generates a single image of the requested type.\"\"\"\n",
        "    label_map = {'invoice': 0, 'receipt': 1, 'chart': 2}\n",
        "\n",
        "    if doc_type not in label_map:\n",
        "        print(f\"‚ùå Unknown type: {doc_type}. Use 'invoice', 'receipt', or 'chart'\")\n",
        "        return\n",
        "\n",
        "    print(f\"üé® Generating new {doc_type}...\")\n",
        "    sample_tensor = diffusion.sample(model, n_samples=1, class_label_idx=label_map[doc_type], size=HPARAMS[\"img_size\"])\n",
        "\n",
        "    # Convert tensor to displayable image\n",
        "    img = sample_tensor[0].cpu().permute(1, 2, 0).numpy()\n",
        "    img = (img - img.min()) / (img.max() - img.min()) # Normalize to 0-1\n",
        "\n",
        "    plt.figure(figsize=(4,4))\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    plt.title(f\"Generated {doc_type.capitalize()}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "def visualize_results(model, diffusion):\n",
        "    print(\"\\nGenerating Grid of Samples...\")\n",
        "    invoices = diffusion.sample(model, 4, 0, HPARAMS[\"img_size\"])\n",
        "    receipts = diffusion.sample(model, 4, 1, HPARAMS[\"img_size\"])\n",
        "    charts = diffusion.sample(model, 4, 2, HPARAMS[\"img_size\"])\n",
        "\n",
        "    all_images = torch.cat([invoices, receipts, charts], dim=0)\n",
        "    grid = make_grid(all_images, nrow=4, padding=2, normalize=True)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.imshow(grid.permute(1, 2, 0).cpu().numpy(), cmap='gray')\n",
        "    plt.title(\"Generated: Invoices (Top), Receipts (Mid), Charts (Bot)\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 1. Train the model\n",
        "    trained_model, diff_manager = train()\n",
        "\n",
        "    # 2. Save the model\n",
        "    save_model(trained_model, \"fintech_diffusion_model.pth\")\n",
        "\n",
        "    # 3. Simulate \"Later Use\": Load the model back\n",
        "    loaded_model = load_model(\"fintech_diffusion_model.pth\")\n",
        "\n",
        "    # 4. Generate a specific new document\n",
        "    generate_single_document(loaded_model, diff_manager, doc_type='invoice')"
      ],
      "metadata": {
        "id": "YYmF8sCdP3QP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load Saved Model and Generate New Financial Documents"
      ],
      "metadata": {
        "id": "4jvYs9gML7tR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.utils import make_grid\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "from PIL import Image, ImageDraw\n"
      ],
      "metadata": {
        "id": "KGWb2isbKmgQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.utils import make_grid\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Re-define necessary global variables and classes/functions\n",
        "# from KlNnmml_DUhZ\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "HPARAMS = {\n",
        "    \"img_size\": 64,\n",
        "    \"timesteps\": 500,\n",
        "    \"batch_size\": 32,\n",
        "    \"lr\": 3e-4,\n",
        "    \"epochs\": 10,\n",
        "    \"channels\": 1,\n",
        "    \"num_classes\": 3\n",
        "}\n",
        "\n",
        "class SinusoidalPositionEmbeddings(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "    def forward(self, time):\n",
        "        device = time.device\n",
        "        half_dim = self.dim // 2\n",
        "        embeddings = np.log(10000) / (half_dim - 1)\n",
        "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
        "        embeddings = time[:, None] * embeddings[None, :]\n",
        "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
        "        return embeddings\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, time_emb_dim, up=False):\n",
        "        super().__init__()\n",
        "        self.time_mlp = nn.Linear(time_emb_dim, out_ch)\n",
        "        if up:\n",
        "            self.conv1 = nn.Conv2d(2*in_ch, out_ch, 3, padding=1)\n",
        "            self.transform = nn.ConvTranspose2d(out_ch, out_ch, 4, 2, 1)\n",
        "        else:\n",
        "            self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding=1)\n",
        "            self.transform = nn.Conv2d(out_ch, out_ch, 4, 2, 1)\n",
        "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1)\n",
        "        self.bnorm1 = nn.BatchNorm2d(out_ch)\n",
        "        self.bnorm2 = nn.BatchNorm2d(out_ch)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        h = self.bnorm1(self.relu(self.conv1(x)))\n",
        "        time_emb = self.relu(self.time_mlp(t))\n",
        "        time_emb = time_emb[(..., ) + (None, ) * 2]\n",
        "        h = h + time_emb\n",
        "        h = self.bnorm2(self.relu(self.conv2(h)))\n",
        "        return self.transform(h)\n",
        "\n",
        "class ConditionalUNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        img_channels = HPARAMS[\"channels\"]\n",
        "        down_channels = (32, 64, 128)\n",
        "        up_channels = (128, 64, 32)\n",
        "        out_dim = img_channels\n",
        "        time_emb_dim = 32\n",
        "        classes = HPARAMS[\"num_classes\"]\n",
        "\n",
        "        self.time_mlp = nn.Sequential(\n",
        "            SinusoidalPositionEmbeddings(time_emb_dim),\n",
        "            nn.Linear(time_emb_dim, time_emb_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.class_emb = nn.Embedding(classes, time_emb_dim)\n",
        "        self.conv0 = nn.Conv2d(img_channels, down_channels[0], 3, padding=1)\n",
        "        self.downs = nn.ModuleList([Block(down_channels[i], down_channels[i+1], time_emb_dim) for i in range(len(down_channels)-1)])\n",
        "        self.ups = nn.ModuleList([Block(up_channels[i], up_channels[i+1], time_emb_dim, up=True) for i in range(len(up_channels)-1)])\n",
        "        self.output = nn.Conv2d(up_channels[-1], out_dim, 1)\n",
        "\n",
        "    def forward(self, x, timestep, class_label):\n",
        "        t = self.time_mlp(timestep)\n",
        "        c = self.class_emb(class_label)\n",
        "        t = t + c\n",
        "        x = self.conv0(x)\n",
        "        residuals = []\n",
        "        for down in self.downs:\n",
        "            x = down(x, t)\n",
        "            residuals.append(x)\n",
        "        for up in self.ups:\n",
        "            residual = residuals.pop()\n",
        "            x = torch.cat((x, residual), dim=1)\n",
        "            x = up(x, t)\n",
        "        return self.output(x)\n",
        "\n",
        "# from BVsgcf64Cm9I\n",
        "class DiffusionManager:\n",
        "    def __init__(self, timesteps=500, start=0.0001, end=0.02):\n",
        "        self.timesteps = timesteps\n",
        "        self.betas = torch.linspace(start, end, timesteps).to(device)\n",
        "        self.alphas = 1. - self.betas\n",
        "        self.alphas_cumprod = torch.cumprod(self.alphas, axis=0)\n",
        "        self.sqrt_alphas_cumprod = torch.sqrt(self.alphas_cumprod)\n",
        "        self.sqrt_one_minus_alphas_cumprod = torch.sqrt(1. - self.alphas_cumprod)\n",
        "\n",
        "    def forward_noise(self, x_0, t):\n",
        "        noise = torch.randn_like(x_0)\n",
        "        sqrt_alpha_bar_t = self.sqrt_alphas_cumprod[t][:, None, None, None]\n",
        "        sqrt_one_minus_alpha_bar_t = self.sqrt_one_minus_alphas_cumprod[t][:, None, None, None]\n",
        "        return sqrt_alpha_bar_t * x_0 + sqrt_one_minus_alpha_bar_t * noise, noise\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def sample(self, model, n_samples, class_label_idx, size):\n",
        "        model.eval()\n",
        "        x = torch.randn((n_samples, 1, size, size)).to(device)\n",
        "        labels = torch.full((n_samples,), class_label_idx, dtype=torch.long).to(device)\n",
        "        for i in reversed(range(1, self.timesteps)):\n",
        "            t = (torch.ones(n_samples) * i).long().to(device)\n",
        "            predicted_noise = model(x, t, labels)\n",
        "            alpha = self.alphas[t][:, None, None, None]\n",
        "            alpha_hat = self.alphas_cumprod[t][:, None, None, None]\n",
        "            beta = self.betas[t][:, None, None, None]\n",
        "            if i > 1:\n",
        "                noise = torch.randn_like(x)\n",
        "            else:\n",
        "                noise = torch.zeros_like(x)\n",
        "            x = (1 / torch.sqrt(alpha)) * (x - ((1 - alpha) / (torch.sqrt(1 - alpha_hat))) * predicted_noise) + torch.sqrt(beta) * noise\n",
        "        model.train()\n",
        "        return x\n",
        "\n",
        "# from YYmF8sCdP3QP\n",
        "def load_model(filename=\"fintech_diffusion_model.pth\"):\n",
        "    \"\"\"Creates a new model instance and loads weights.\"\"\"\n",
        "    if not os.path.exists(filename):\n",
        "        print(f\"‚ùå Error: {filename} not found.\")\n",
        "        return None\n",
        "\n",
        "    model = ConditionalUNet().to(device)\n",
        "    model.load_state_dict(torch.load(filename, map_location=device))\n",
        "    model.eval()\n",
        "    print(f\"‚úÖ Model loaded from {filename}\")\n",
        "    return model\n",
        "\n",
        "def generate_single_document(model, diffusion, doc_type='invoice'):\n",
        "    \"\"\"Generates a single image of the requested type.\"\"\"\n",
        "    label_map = {'invoice': 0, 'receipt': 1, 'chart': 2}\n",
        "\n",
        "    if doc_type not in label_map:\n",
        "        print(f\"‚ùå Unknown type: {doc_type}. Use 'invoice', 'receipt', or 'chart'\")\n",
        "        return\n",
        "\n",
        "    print(f\"üé® Generating new {doc_type}...\")\n",
        "    sample_tensor = diffusion.sample(model, n_samples=1, class_label_idx=label_map[doc_type], size=HPARAMS[\"img_size\"])\n",
        "\n",
        "    # Convert tensor to displayable image\n",
        "    img = sample_tensor[0].cpu().permute(1, 2, 0).numpy()\n",
        "    img = (img - img.min()) / (img.max() - img.min()) # Normalize to 0-1\n",
        "\n",
        "    plt.figure(figsize=(4,4))\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    plt.title(f\"Generated {doc_type.capitalize()}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Load the model back\n",
        "loaded_model = load_model(\"fintech_diffusion_model.pth\")\n",
        "\n",
        "# Initialize DiffusionManager for sampling\n",
        "# This requires HPARAMS and device to be defined\n",
        "diff_manager = DiffusionManager(timesteps=HPARAMS[\"timesteps\"])\n",
        "\n",
        "# Generate a specific new document\n",
        "generate_single_document(loaded_model, diff_manager, doc_type='invoice')"
      ],
      "metadata": {
        "id": "zBd6I2DVKgwh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "ee297749-6c61-4286-cf32-6b284f93ad24"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Model loaded from fintech_diffusion_model.pth\n",
            "üé® Generating new invoice...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUgAAAFeCAYAAADnm4a1AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAALBNJREFUeJzt3X+QVXX9x/H3uvzY3bu7oMMiAsrKgpIMU0r+GH+UP1AQnLJUQE0hC80BHS1GMzNl8sdYzQSCqP0yJZkRw2Yo0dK00ammstQwR1tp0dRSfggCy49gP98/+u4d7+e8P+2Lc+5K2vMx40wczj33c84999Pl/T6f97smhBAMAJCxz94eAAD8t2KCBIAEJkgASGCCBIAEJkgASGCCBIAEJkgASGCCBIAEJkgASGCCxPtOa2urzZw5c28PY4/MnDnTWltb9/YwsIeYIN9DHR0dNmfOHDvkkEOsoaHBGhoa7LDDDrPZs2fbn//85709vKpauXKl3XDDDXt1DDU1NTZnzpy9Oga8v/XZ2wP4X/Gzn/3Mpk2bZn369LHzzz/fPvzhD9s+++xjL774oj344IN2xx13WEdHh40YMWJvD7UqVq5cabfffvtenyT/W3z3u9+1rq6uvT0M7CEmyPfA6tWrbfr06TZixAj75S9/aQcccEDF39966622ePFi22ef/94f9Fu3brVSqbS3h/G+1bdv3709BOTw3/uN/AD5xje+YVu3brW77747MzmamfXp08cuv/xyO/DAAyu2v/jii3b22WfbfvvtZ3V1dfbRj37UVqxYUbHPD3/4Q6upqbFf//rX9sUvftFaWlqsVCrZpz71KVu7dm3mvR5++GE74YQTrFQqWVNTk02ZMsX+8pe/VOwzc+ZMa2xstNWrV9vkyZOtqanJzj//fDMze+qpp+ycc86xgw46yPr3728HHnigXXnllbZt27aK199+++1m9u9/5nb/162rq8vmz59vY8eOtbq6Ott///3tkksusbfffrtiHCEEu/HGG2348OHW0NBgJ510Umase+JXv/qV1dTU2LJly+ymm26y4cOHW11dnZ1yyin28ssvl/ebM2eONTY2WmdnZ+YY5557rg0ZMsR2795d3rZ48WIbO3as9e/f34YOHWqzZ8+2jRs3Zq5pHIPs6uqyBQsW2Lhx46yurs5aWlps0qRJ9vTTT1fs96Mf/cjGjx9v9fX1tt9++9n06dPt73//e+7rgD0Q0OuGDh0aRo0atUevef7558OAAQPCYYcdFm699dawaNGi8LGPfSzU1NSEBx98sLzf3XffHcwsHH744eHkk08OCxcuDF/60pdCbW1tmDp1asUx77333lBTUxMmTZoUFi5cGG699dbQ2toaBg4cGDo6Osr7zZgxI/Tv3z+0tbWFGTNmhDvvvDPce++9IYQQLrvssjB58uRw8803h7vuuit87nOfC7W1teHss88uv/43v/lNOPXUU4OZhSVLlpT/6/b5z38+9OnTJ8yaNSvceeed4eqrrw6lUikceeSRYefOneX9vvrVrwYzC5MnTw6LFi0KF110URg6dGgYNGhQmDFjRo/X0MzC7Nmzy39+4oknytdq/Pjx4dvf/na44YYbQkNDQzjqqKPK+z355JPBzMKyZcsqjrd169ZQKpUqjnn99dcHMwsTJkwICxcuDHPmzAm1tbWZc5kxY0YYMWJExfFmzpwZzCycfvrpYf78+eFb3/pW+OQnPxkWLlxY3ufGG28MNTU1Ydq0aWHx4sVh3rx5YdCgQaG1tTW8/fbbPV4DFMME2cs2bdoUzCyceeaZmb97++23w9q1a8v/dXZ2lv/ulFNOCePGjQvbt28vb+vq6grHHntsGD16dHlb9wQ5YcKE0NXVVd5+5ZVXhtra2rBx48YQQgibN28OAwcODLNmzaoYwz//+c8wYMCAiu0zZswIZha+/OUvZ8b87jF2u+WWW0JNTU145ZVXyttmz54dvP//feqpp4KZhfvuu69i+yOPPFKx/a233gr9+vULU6ZMqTivr3zlK8HMCk2QH/rQh8KOHTvK2xcsWBDMLKxatSqE8O/rPGzYsHDWWWdVHG/ZsmXBzMKTTz5ZMcbTTjst7N69u7zfokWLgpmFH/zgB+Vt8QT5+OOPBzMLl19+eWbc3ee7Zs2aUFtbG2666aaKv1+1alXo06dPZjuqj39i97J33nnHzMwaGxszf3fiiSdaS0tL+b/uf5Zu2LDBHn/8cZs6dapt3rzZ1q1bZ+vWrbP169fbxIkTrb293V5//fWKY1188cUV/4w94YQTbPfu3fbKK6+Ymdmjjz5qGzdutHPPPbd8vHXr1lltba0dffTR9sQTT2TGd+mll2a21dfXl//31q1bbd26dXbsscdaCMGeeeaZHq/HAw88YAMGDLBTTz21Yhzjx4+3xsbG8jgee+wx27lzp1122WUV53XFFVf0+B49+exnP2v9+vUr//mEE04wM7O//e1vZvbvsMA555xjK1eutC1btpT3u//++23YsGF2/PHHV4zxiiuuqIgfz5o1y5qbm+2hhx5KjmH58uVWU1Nj119/febvus/3wQcftK6uLps6dWrFtRoyZIiNHj3a/cxQXSRpellTU5OZWcUXrdtdd91lmzdvtjfffNM+85nPlLe//PLLFkKw6667zq677jr3uG+99ZYNGzas/OeDDjqo4u/33XdfM7NyXK+9vd3MzE4++WT3eM3NzRV/7tOnjw0fPjyz36uvvmpf+9rXbMWKFZmY4aZNm9xjv1t7e7tt2rTJBg8e7P79W2+9ZWZWnthHjx5d8fctLS3lc8urp2tlZjZt2jSbP3++rVixws477zzbsmWLrVy50i655JLyBNY9xkMPPbTieP369bORI0eW/96zevVqGzp0qO23337Jfdrb2y2EkLkG3Uj89D4myF42YMAAO+CAA+z555/P/N3RRx9tZmZr1qyp2N79OMjcuXNt4sSJ7nFHjRpV8efa2lp3v/D/HTW6j7lkyRIbMmRIZr8+fSpvhf79+2ey6rt377ZTTz3VNmzYYFdffbWNGTPGSqWSvf766zZz5kzpMZauri4bPHiw3Xfffe7ft7S09HiMonq6VmZmxxxzjLW2ttqyZcvsvPPOs5/+9Ke2bds2mzZtWq+Pr1tXV5fV1NTYww8/7I7Z+1cJqosJ8j0wZcoU+973vme///3v7aijjupx/5EjR5rZv38hTJgwoSpjaGtrMzOzwYMH5z7mqlWr7K9//avdc889duGFF5a3P/roo5l93/3P4ngcjz32mB133HEV/1yPdT8P2t7eXr4eZmZr167N/HLtLVOnTrUFCxbYO++8Y/fff7+1trbaMccckxnjSy+9VDHGnTt3WkdHx3+8zm1tbfbzn//cNmzYkPwV2dbWZiEEO/jgg+2QQw6p0llhTxCDfA9cddVV1tDQYBdddJG9+eabmb8PUd+0wYMH24knnmh33XWX/eMf/8js7z2+05OJEydac3Oz3Xzzzfavf/0r1zG7f8W8e7whBFuwYEFm3+5nJuPHXaZOnWq7d++2r3/965nX7Nq1q7z/hAkTrG/fvrZw4cKK95s/f36P46yWadOm2Y4dO+yee+6xRx55xKZOnVrx9xMmTLB+/frZbbfdVjHG73//+7Zp0yabMmVK8thnnXWWhRBs3rx5mb/rPtanP/1pq62ttXnz5mXukRCCrV+/vsjpQcAvyPfA6NGjbenSpXbuuefaoYceWl5JE0Kwjo4OW7p0qe2zzz4VMb/bb7/djj/+eBs3bpzNmjXLRo4caW+++ab99re/tddee82ee+65PRpDc3Oz3XHHHXbBBRfYEUccYdOnT7eWlhZ79dVX7aGHHrLjjjvOFi1a9B+PMWbMGGtra7O5c+fa66+/bs3NzbZ8+XL3F9348ePNzOzyyy+3iRMnWm1trU2fPt0+/vGP2yWXXGK33HKLPfvss3baaadZ3759rb293R544AFbsGCBnX322dbS0mJz5861W265xc444wybPHmyPfPMM/bwww/boEGD9ujc8zriiCNs1KhRdu2119qOHTsy/7xuaWmxa665xubNm2eTJk2yT3ziE/bSSy/Z4sWL7cgjj6yIK8dOOukku+CCC+y2226z9vZ2mzRpknV1ddlTTz1lJ510ks2ZM8fa2trsxhtvtGuuucbWrFljZ555pjU1NVlHR4f95Cc/sYsvvtjmzp3b25fhf9t7nzj/3/Xyyy+HSy+9NIwaNSrU1dWF+vr6MGbMmPCFL3whPPvss5n9V69eHS688MIwZMiQ0Ldv3zBs2LBwxhlnhB//+Mflfbof8/nDH/5Q8druR1qeeOKJzPaJEyeGAQMGhLq6utDW1hZmzpwZnn766fI+M2bMCKVSyT2HF154IUyYMCE0NjaGQYMGhVmzZoXnnnsumFm4++67y/vt2rUrXHbZZaGlpSXU1NRkHvn5zne+E8aPHx/q6+tDU1NTGDduXLjqqqvCG2+8Ud5n9+7dYd68eeGAAw4I9fX14cQTTwzPP/98GDFiRKHHfB544IGK/To6OjLj73bttdcGM/uPz7EuWrQojBkzJvTt2zfsv//+4dJLL808o+g9B7lr167wzW9+M4wZMyb069cvtLS0hNNPPz388Y9/rNhv+fLl4fjjjw+lUimUSqUwZsyYMHv27PDSSy/1eA1QTE0I9MUGAA8xSABIYIIEgAQmSABIYIIEgAQmSABIYIIEgAQmSABIkFfSLF++PLNtyZIlmW39+/ev+LP3mKW31M1bu9vQ0JDZtnPnzoo/x0UWvH1Sx/J4bQ/iSjxe4YAi/Ua6K/50e3d17v90fG8cXoWXHTt29DgG75p5x/c+J+8zfnfFbTOz7du3S8fPW6Emfr/UuHbt2iUdL74P1M9XvWbK5+l9T7z7OO/n5B3fO5Z3b3jfk/g9311Srpt33t5n4m3zvuuKurq6zLalS5dKr+UXJAAkMEECQAITJAAkMEECQIIc9fzFL36R2eYFYVPVmt/NC8B6x1KCw15w3gv0ey08vf2UwLW3j3csNbAf10z0qMkoLxkSXzM12O2dp/c5eZ9nfM28QLkX6PeumbKfkjRIjUNJ5qQKACu8e8O7b6v1OpX3XfWOHydezbRkl3d/eufk3Y/efeB9TvE5eOPy2p2o+AUJAAlMkACQwAQJAAlMkACQICdpvAZBXkA3Doh6+3jB/7yJDy+A7L2nF/T1jq+sKFFXk3hBcCUJ5B3LS0J4wW3vnJRVId7xPd74PXGwXE3IeNdMubbVTF6YZT9j7z5Tk3De2JTkonfeajJQSfCoq1W8+11Jxnq88/be00umKdfbu8/ilWp7gl+QAJDABAkACUyQAJAgxyCbm5sz2zZv3pzZpsSCvFiCF4fwqtB4saC81LhhTK0IUyRGFfPiQOpD8spDzmrFFu9z8q5H3mo43ji8h9Pjz069f9T4dHzNvH28Y3nXzLunlIej1TifMn7vPdXP0uPFCOPXKlWeUtSqP0pT1q1bt0rv6eEXJAAkMEECQAITJAAkMEECQIKcpNmwYUNmm5cQUMq6qw9ae4Hg+HhF2g54CYH6+vrMtjhg7AW3veCzWgFGqVDkXR8vkO1d7/i1XsWfP/3pT5ltXhUU5UF0M60ajpLcUY+vJkLUQH+8Ta18o1ZdUvZTWzWo93uc7FKTKN71V5ItynfJTG+5cPLJJ2e2xedezSSuGb8gASCJCRIAEpggASCBCRIAEuQkTd6n4otUB/ESDl7iJlakWo0X3FZaLnjXQlltYJa9HupYPXmrrHifk5oAU1bJeJ+5skImNbb4Gqmv865/3pYC6ufknWfe/dTvodJfXP1M1FVQ8fVQV2ep95mStFLbPKj4BQkACUyQAJDABAkACUyQAJAgJ2lKpVJmm7ciQyk/5FGSF957FikJ5b1WCbyrq0nyXgu1tJk3fuU6Kn2szfSEjLIySl1ppPZDVl7nrQRSV7oofbeL9PVWWkuo95S6yiem9kf3KAkYtX2Gx0uceeON91M/JxW/IAEggQkSABKYIAEggQkSABLkKK3Xf8YLpKolvpTXKQFvNVDu8QLGSt9n73VqYkU5Xt7kTmoccVJGKYlmpgf/lf7KSj/wFLUsmrKPOo44CaGs5knt51GSXWpvaLW/dfwZe/eKeh8rq5S8JJ/6WSor2rzXevvknZPM+AUJAElMkACQwAQJAAlyDNKLJyitAdR//6sPIMcxBjVep5bk9x5+j8ehnpNXGUXpy+yNVY2tKO0J1JiV109427Zt0nsqn4vajkPpSa22Bcj7mXvU1hjqA9Px2NQ2IR4lvqg+1K72Eo/nCG8f9T297453TvE9VKT1iYdfkACQwAQJAAlMkACQwAQJAAmFkjRekF15SFsNWivBVS/hoJaNVwPq6oPnMfWBbCUJpI7BS0IMGDCg4s8DBw7M7NPa2prZpiZkFGrlIVV8jdTgvJqEyNu6Qn0QXam6pD50rrYwURYuqAsvlG1qYrFIz/H4Oqp9w1X8ggSABCZIAEhgggSABCZIAEgoVM3HqzYSB1Lz9tM208q6q/1zPepT/fF+3jmpfZmVZIt33l7w3zt3tXVCrLOzs8d99kR87t55e9dHXZ0SH09NyKitN5RjVTO5472HeixvHMp1VCr+eONKvTbvijO1wo+SAFNXoan4BQkACUyQAJDABAkACUyQAJAgJ2mam5sz25RVLF5g1eux7QWVvddWcyWHWjoqfk+lD3RqP+U9vaSKd3y1v7Wy6kQJupvpyYp4bGpZOrUNgHK8vKuzzLLXsUhfbzVxpvQSV1eKKEkaNVnq8e7j+DyL9Hf37jMvKeyVhFOOpeIXJAAkMEECQAITJAAkMEECQIKcpPGCsspKFC+ArCZH6uvrM9vioKwXgFV6Q5vpT9grqzbU4L+yekFNLqil2eL3LFJeKm9gX020qKXwlGumJoaUBJhaeqxIQkBZiaJ+5kXu0Zi6kia+ZuqqFnVFm5KQyVvmLYVfkACQwAQJAAlMkACQwAQJAAlyksZ7it0Tr35Rm4J7zdu94Gr//v0r/uwFbr0Act6EjHc8tT+MWjoq77HylnHyxuBtK7ISJe+x8q6eKrRaQiitpR5fTQgoCRilzJv3OnUcahLLoyTw1HtFXXHjzRtxwtd7HT1pAKAXMEECQAITJAAkyDFIjxcvUvbxYh9efEGJ+6gtF7wHxb24qvcQe942EurD10pMU+3r7YmvR5FWBN5+So9nj/pwd974qxor9q5HfPwicWf1QW6F2oteeVBcjZF77TiUuGeRalzeOXnHa2hoqPiz9/1VHjBP4RckACQwQQJAAhMkACQwQQJAgpykUQOucaDWS754QX2v7/a2bdt6HJeaIPD287bFD6KbaUFeL6jsnbu3n9J325M3OaJWpvGoQfb4PdSWBXkfei5yTmqLC+V1asJESeYoSVAzvb91TG2foT7IrfC+Xx61TUX8HfDOSa0e5uEXJAAkMEECQAITJAAkMEECQIIc2faCn14FnjgIq1bl8I4/cODAzLY4KKv2BFZ7VCuBd+9Y3rXwkihKMkHtR632svbGofCO7yXOlCSE2hqjSM/unsaQ2qa8p1qNqEj/b+U+yzt+7/hqwk1dyaSsNirSZkPp+e69jmo+ANALmCABIIEJEgASmCABIEFO0nirSbyAaJz4UPYxM1uzZk1mmxdEzptw8ALIXnDbO368n/q0/rhx4zLblMSEWhJNLeOktIxQEwLq6hHlPZXXpcYRUxNiaomveD/v+GriKW/iRk0Mqe+pjEMtq6eWdYspq2HMtDYYZtlzL7KiysMvSABIYIIEgAQmSABIYIIEgAQ5oumtavFWVcT9K9SVLl6SwwvexsHhvGWXUq9VVmh4T/R7Y/XOvZq9rNVVM3nLqallopTEk/ee3ljVVRXVep2Z1qNH6QO9J++pJFu8pEeRxJDSZ0ctN6f08fGSKmpCxqOcZ97Vayn8ggSABCZIAEhgggSABPkf5148yotNxNV8vDiH+rCoEk8o0uPZi00ocTHvWnjxEeXBVo96TmpvZTXGo8g7DjWeVs0HuT3efaC0NlBj3WrlGOVB67zfCe9Y3jY1duldn7zVfDxqXFUZr7ePVz1MHlvuVwLABxwTJAAkMEECQAITJAAkyEkaL0itBG+9wG2R4HO8n5poUSsDKYFgNRCv9ltWgudq4kYJ2KsBcI96HZXEkHpOSvBfeXDZzL+PlVL+6oPi6nuqrUhiamLLE49NbXmhJjmU7756b6vi41UzIWnGL0gASGKCBIAEJkgASGCCBIAEOUnjJWS84K3SPkBt31DN4L8nb9l4pWKOmV65Jx6vmjBR94sV6fGsrkiKX6u2P1ASJt5r1c9SPX78WnUljbqfmqBS9vGurVLdKO+qpdR7Kj3rlVVLqfdUPqdq4xckACQwQQJAAhMkACQwQQJAQqEmsl7AVUmQeMHbww8/PLNNCc7X1dVl9lFLa3nJImUlhLeP2p7Ao6wOUle/KEkCbx+1LL3aZkDp8awmCZTPU01YqX3a43tULdFXpC923sSWugotvmbeZ6mep9KGQb0+RUqnxePN2w88hV+QAJDABAkACUyQAJDABAkACXKSxgt0NjQ0ZLbFAW+1fNX69eul94yDz16w2AsOx71yzPyEgFLCyhu/N1Yv4O29Nk52qX18PF7iKb4eXmLLo650UZIoan90taxYzFvVVWTFkJJ0q+ZKHW+bd83UcmHe+JWe8l7iVe2LrbzOs3379sw27zp632Glf7n3nVDxCxIAEpggASCBCRIAEgq1XFBiB2pLhJaWlh6P5R1P6WNtpsVkzLS4ofogunfNlBiSN1alOkvq+Mq48sb+UpSHhr3jq/HR+N7zPrci5ffjz1g9lvqZ561Ck7dlhFn2HNTKOurD3fHx8z70n3pPhVrtSMUvSABIYIIEgAQmSABIYIIEgAQ5eukFZfOWdfe2vfDCC5ltauWYmBoA98bvBa6VgL237eCDD85sUx6YVh8QzlvBRg1aF6myEo/NOyf14XFvHPGD4dW8Pt5r8ybEUvsp7TjUVgdqVSTlWF4yTV2koCTm1EpVeVuYeOetJqPc4+V+JQB8wDFBAkACEyQAJDBBAkBCoSSNJw7MegHkIj2G866k8QK1anA7DiKriQqv+oj3nqVSqeLPavURtRd0PH51tUdv9yZWX+d9xkplGu/6q+OIt6lJIOX6q9QEp7o6RbneRZJA8Weg3lNFEmAx7xzV1VkefkECQAITJAAkMEECQAITJAAkyEkaL3GgPBWvloP39vPK6MfH9xIyXlDfO5aaJIj384LK3vXxViB4yaJ4m1r+KW9wu9q9g5VkRd4VOGb+9Yg/Y+/zVRN4yjjUa6YmwPK2MVBXp3j7xZ+B2ppEHWt8nmpf7CLlzuLPwLsPWEkDAL2ACRIAEpggASCBCRIAEvI3a7D8wX41YO/1vMn7VLzan1tZqaCWAduyZUtmW7xqxkxbWaReMy/gHZ9T3kRIaj8v6RYnqIqUoPPGGycT1DJdeRMO3vi9Y9XX12e2qStRlHJh3jmpZdFiai9xldILXXmdWf4klncveuep4hckACQwQQJAAhMkACQwQQJAgpyk8ZIjSkJDLTPmBaQ9cRBWbXivrnDwKOXCvOSCd82U13rBaO/4aiA7bzkyldKvSB2/RwniK/2RUsdSyoUpya/UsbxtyoqYIu+prN5RS7jlXX2krv5SKclR7/gkaQCgFzBBAkACEyQAJMgxSC+WqMRzvBihF0sYO3ZsZlvesutq2XiP0otbfajao1S+UeNMHmX8aqsA70FftV9x/J7q9VHjx0oM0qPGxZRYtxojVCkLEoq0eYjHq8Yg1ao8SiUvNReQ97vv8R4eV/ELEgASmCABIIEJEgASmCABIEFO0ngBeyUQ7AV4vYTP5s2bM9uUNg9KhY/UOFTKg9wq77Xx9fAebFV6hJtpbQDU1+WtEmOWPU91cYD6IHd873mBeC/JobbeiI/v3bPetahmj2r1oXOPkgzJ23LETGu3oibO1CSQ8h1WF46o+AUJAAlMkACQwAQJAAlMkACQICdptm7dmtmm9K1Wq2sMGjQos00J8qorOzx5VwioqyXyVjJSkyhq5ZV4HOr1ydt3O/XavMdXkihFVmh42+KkpFoZyOON3/sO5E3+qecUH99Lgqp95pXje/e/MmeY5U92VXMFjhm/IAEgiQkSABKYIAEggQkSABLkJE1DQ0NmmxeEjYPbXiDY63f93HPPZbYpgWA1mOvxAvveeGNqoLmtrU16bRwY98YV94FOvaeSEFBLihVZMZSX2rM77+u8/ZSkmLrSSE2YKD3Zi6xkUkrmqT221f7W8T1UpNWBSlmxRcsFAOgFTJAAkMAECQAJTJAAkCAnadRkSJy48QLUXnJH6Xlrlg3CqmXY1Kf6lVUmal/svD2Gi6yk8cSlwLwxFOkfovRmUZMcamIl/jzV0mPqvRGrds8b775V+ux4Zd28c/f2ixN9Smm81DiUFWzVPJZZ/mumfL4p/IIEgAQmSABIYIIEgAQ5Buk93O3FBOJtXnyhsbExsy3vQ8lF4oHbtm2T3iOO8ajVfLyH65Uy+kUqkniVV+Ljq9esSJsKhfeZe/eZ8lq1rL53Tt62+Hp4MT21lYK6X3xfqZ+Tdz96CwviRRDqsdRYtHIfq8dSx9Hr92ivHh0A3seYIAEggQkSABKYIAEgQU7SNDU1ZbZ5D2Dm7Y3b2dmZ2VYqlTLblAdD1eojapWP+D28ij/eNrVUfUx9wFl9wFZpGaEmhtTAfnw8NRBfV1eX2aYkbtQH3dWFBfHYvHtFqZiTGpvy2SmJnNQ27zzja1vkQW6Pcp954/K+J3mvrVqtScUvSABIYIIEgAQmSABIYIIEgAQ5euklUZRkiLrCwXvy31vpEgfLveSI955e0FcNSMerKLyguxfEVyvMKCtzvGN511/pdayuBKpm72aPulrCW3kVn6fS2zpFqSCkJpm8e0qtMBPfG2plI/U7Fo83byuIPXmtsk+R3vYx9d5W8QsSABKYIAEggQkSABKYIAEgQU7SqAH1eD81AHvEEUdktnnlwuJVFWoiRH1aXwnse+/pXQtvHF4SRUkIeLxAv5JEUQPg6jkpiYO8q0nMtLJ0al9vtRSeokiZLuV4apsQbxze/a6sQstb2qwIdaVL3gRhkbHyCxIAEpggASCBCRIAEpggASBBTtKoKwTiIK8a9N24cWNm29q1azPb4uCzWrLMC1qr/YTj1yo9TMz8hI+yqsILKntlwPImHLxVS2oSxaN8xt41866Pl5jwzl1ZdaIm69R7Q6EmPpRrpvbsUVenxMdTE5cepb+49930ztv7znnj8JK28X5qOT4VvyABIIEJEgASmCABIEEOtHixobztDrz4xb777ivtF8dRvPfzYg5enEN9bRyP8h5c9h4A96rQeNdRiZGoFVW8/eJrprYFqOYDwmqM0Guz4VEevlZ7fStx7CKVe9TezXkfrvcor83bSkHdpi5IUBdeeJQ2FTwoDgC9gAkSABKYIAEggQkSABLkJI1aNSdOhqgVW1atWiUdPw4Eq1VcvCSNkgTyqL2JjznmmMw2LyEQJ3i8Mah9nz3xeXrJKTW4Xc3EkDcOtYJQ/Fr1dd5D8sp1VB829u4ztbWH8nC6mrjxPqd4HEXuM6X/tHcstd+1d82Uc1cf1FfxCxIAEpggASCBCRIAEpggASChUJJGWX3hrRzxVLN8vXcsLzivBsrj/dSxeqtrlOtYZIWD8tq8fZRT75n3WN69oa7aUFenxNTPJD6+mmhRKYk+JfmV2qa8Z97PUn1P7zPyXqdWTlJWgBVJyHj4BQkACUyQAJDABAkACUyQAJAgJ2m8Uu9ecDUO/KqBbK+cemdnZ2abEmhWA9lqoF8pVV+k13R8/CKrGZRkgtLH2kwv8aWWwlN4SRS1FJvCO0+l9UC1S4N511a5H4uUO1NWoXkrgbxjKWX71BUy6jl5q9Di13r75E3omfELEgCSmCABIIEJEgASmCABIEFO0qiJjzhQ6+3jBeK94LAnDriqT+arwee8KxXUfs5ekDpOgOXtyWymlS1Tr5naz9krWxYnBNRVOV6yTgniqyW/1HJh8Tl556iW0POOr6yk8e4ftaeR9znFn7H3Ou881WsWv6faF1tJ9qrj8Mal9BxK4RckACQwQQJAAhMkACQwQQJAgpwNUAPNcXBVfbJdLe0Uly1Tg+JqSSi1x01P4ypyfO9aqOXaPOq5x4qseojPU11h4l0fZRxqzxg1CRcfX13ho94/3rb4PPP25zHTrof6+ao9jOL91P48ao8nT7yf9zkVKUvHL0gASGCCBIAEJkgASJBjkN5Dqx6lfYD3MPBHPvKRzDYvVhm/1ntwtkgJd6VqjvqwrtpuQqE+lKxUiVHiX2b544Fm2XiU91mqx1c+E7XykBojjI+nVidS76m8cVU1Hqg8PO7lB9T7WLkeam9rNY/gHS/e5r2Oaj4A0AuYIAEggQkSABKYIAEgQU7SqNVMlECzF0jdsGFDZpsX3F63bl3Fn70ArPpQtVqlROFdH493zZQ2Et61UErQm2UD2UrvbzP9+uR9MF8Juu/JOGJq321l/N4DyB41SeB9BsqD4t71UdtPxK/1ro+a0FCq7ahJSu/7qi4cUSpVqQ+de/gFCQAJTJAAkMAECQAJTJAAkCAnadavX5/Z1tTUlNmmPK3vBW9bWloy27yAsRKQVhMtXsLEC57nbYGg9uLOu2pDfc8i1UxiatJNSTioqyqUZIXa11ttAxC/Vk1sqStRlEpV6v2vthOJeeP3VsypVYWUSl5qKwV1P2VcagLVwy9IAEhgggSABCZIAEhgggSABDn7UF9fn9mmlEFSA7y/+93vMtvytgpQVimkxuGJx6EmQsaNGyeNLW8SRU2Y5KX2slZWp6gJK3VVRUwtbaaUTvO25S2NZ6aXKFPaVHjX0UusKCuevHvR+0zy9orP274kRUlaqS0dVPyCBIAEJkgASGCCBIAEJkgASJCTNOqqBCVJUKT/STyOvD2BU7yyVsrKFrW0U96VLmoPZk98PdQ+xOqqlrwBe3WFUt4kkHqtvf3iz9O719UVIOq1VcreqfeZ+tkpr1NK9HnU76a3n3ee3n7xOam9j1T8ggSABCZIAEhgggSAhEItF/LyjuXFeJTy8mr1DqWKTmocSmUXL2aiVgvKSy21n7csvbefF6NVP7tYkco0eR84znvu6kPhHrXqT3zNCvVzzln5xqPE/rxtansONa6tfodjVPMBgF7ABAkACUyQAJDABAkACXLGQK0sogR+1YohysO0atBdfYBXCRhv3749s49XUcVLyKitAWJF+iHH41cr8njj8s4z70PPamJIuT5FFgco10Nt1aBSknXeZ672+lbaPKifSd4e1Sq1LUvez7hIBSF+QQJAAhMkACQwQQJAAhMkACQUquajtFzwdHZ2ZrY1NDRktinJEG8Maql9VRzMLlJZR0msqH2xld7EZvmD22pCSQmC5+1znNpPSQKpK1GUFh3esYq0t1ASiUq/cTP9OuY9vroiLG6XoVYeUr87XjInHluR1ioefkECQAITJAAkMEECQAITJAAkyEkaNZAaB2a9ALJXfmjkyJGZbcrT+tXug+sFn5VyZx4vuO2Jz0Edf94VMerriqxAUM5JTTJVsz963hJi6komtXWIWgoslnelkXd8NeGmtlbJmwhVS8l5pfaUsnRq0tPDL0gASGCCBIAEJkgASGCCBIAEOUnjlbnyArVxENzbxwueVzPoq5YBU0sqxUkldWWB2ktF6eVRzZUoRcrBeapZhkpdnRVfM/VaqwmH+D3VvilFenEripQZi8+hSPJISXyoZQ29a6vON3kTWyp+QQJAAhMkACQwQQJAQqEmzUqsLK7wYaY98GmmVS5R4xLqA+seJUboydsPudrxwDg+WqTyULUfxFWOpTzQrN4HeeOv1a4S44nfs9rnpFTzUePfXqw4fm2RHvDqOSmxYrWqkIdfkACQwAQJAAlMkACQwAQJAAlyFFWtghIHTb0AqdoHV+0B3NMYUvI+wOu9znt43DuW2is7VqQvuVJhSaU+hK8Ez4skOeLjVbNvu/J+qfdUHmpPyVttR63wEx+/yPi918ZJz7znbVbdxQzeQ+cqfkECQAITJAAkMEECQAITJAAkFOqLnbe6RpF+v0r7Ay+hVCSIH7/WG6v6nl7iSVkVUiThEAfPvbF6q4rUaiye+DzVCk7qOSnJorw9vFOvjSnVrPbkPeP7Sk1eqN8n5fgedfVUvJ+a3FH72HvJ3ViRnvXu8XK/EgA+4JggASCBCRIAEpggASBBTtJ4AVKltJDaSiFv+wB1hY8aaFZ7RivH8ijnqa6WUAPe8X7e69SAvTqOvCXQ1FUh8XsWaX+gJObUe1a9pxRF+rt734t4m3d87zy9Yyll6ZRVXWZ+gjDv6hqvvGLeXuhm/IIEgCQmSABIYIIEgAQmSABIkJM0Xh8ZTxy4Vssnedu84K3S29cL5qoBaY+SwPBWiqglm5QyVGoSRb0eeY/v8Y4fB8aLlFhTEj5qLxW1T3s8frVEn7piSF2NpVATYvE5FCkztn379h7H4X2/vCSKd3y1n008Du+cvLGq+AUJAAlMkACQwAQJAAlMkACQICdpvJ4rXq8HJSGgljZTSpSpK2TUoK+6akB5nbpCIFakH4eSeFKPX80Sa+pKFO865r2n1BJ0SnJEKVOX2k9NnCll9dRrppynulJHTTLFinw31Xu0vr6+x3E0Njb2uE8KvyABIIEJEgASmCABIEGOQaqlzPNWjlErnsTjUKvvqHEaJbbixRbVvtjKQ+ze8T3qg+7x8dV4o/qZ5K06490H3oPEygPNSp/m1LG86xjHxdQFD+p75q3wk7eXu5n2OeX9Hppl469FKlx53yfv2m7YsKHiz2+88UZmn4aGBmkc7thyvxIAPuCYIAEggQkSABKYIAEgQU7SDB8+PLPttddey2yLH9ws0hvXS6zED6erCQdP3vYK3sPAajJKaV3hVU7yAuxe0Fp9wDamPqzrXdtt27b1eDy1yo1HSS544+rs7JSOryTd1IeUvcoxauIjvkbesdTEn3dOcdLES6J495762SmLA0qlUmabd/+oFb+2bNlS8eexY8dm9lmxYkVmm4pfkACQwAQJAAlMkACQwAQJAAk1oUjzXQD4AOMXJAAkMEECQAITJAAkMEECQAITJAAkMEECQAITJAAkMEECQAITJAAk/B8wtRU3XoqbmgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
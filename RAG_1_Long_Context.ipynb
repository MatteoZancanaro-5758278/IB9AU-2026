{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOyO8pNRvz8n0Da6rLPuNLY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RDGopal/IB9AU-2026/blob/main/RAG_1_Long_Context.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Long Context vs. RAG\n",
        "We will first explore an alternative to traditional RAG (Retrieval Augmented Generation). Instead of chopping documents into small pieces (\"chunking\") and storing them in a database, we will leverage Gemini's Long Context Window.\n",
        "\n",
        "\n",
        "**Why this matters:** Traditional RAG is like using a search engine to find a single page in a book. It‚Äôs fast but can miss context. Long Context is like asking an expert to read the entire book before answering.\n",
        "\n",
        "**The Advantage:** For \"small\" datasets (under ~1,000 pages), this method often yields higher accuracy because the model sees the entire document structure (tables, footnotes, and headers) intact.\n",
        "\n",
        "**The Technique:** We will use Prompt Engineering to force the model into an \"Auditor Mode,\" requiring it to cite specific sections for every claim it makes.\n",
        "\n",
        "**The Scenario:** You are building a compliance tool for New Horizon Solutions. You need to audit employee records against company policy (Benefits & FMLA) to ensure no rules were broken.\n"
      ],
      "metadata": {
        "id": "N4AXviZftENa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKYsObNVo_Q5"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "import time\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Setup (Use the standard library)\n",
        "# Get your API key from https://aistudio.google.com/\n",
        "\n",
        "from google.colab import userdata\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GEMINI_API_KEY')\n",
        "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])"
      ],
      "metadata": {
        "id": "C6fwZe_lpOT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Upload Files\n",
        "print(\"Uploading files...\")\n",
        "# Ensure 'Benefits.pdf' and 'FMLA.pdf' are in your Colab files folder\n",
        "benefit_file = genai.upload_file(\"Benefits.pdf\")\n",
        "fmla_file = genai.upload_file(\"FMLA.pdf\")\n",
        "\n",
        "# 3. Wait for Processing (Crucial Step)\n",
        "print(\"Waiting for processing...\")\n",
        "while benefit_file.state.name == \"PROCESSING\" or fmla_file.state.name == \"PROCESSING\":\n",
        "    print(\".\", end=\"\", flush=True)\n",
        "    time.sleep(2)\n",
        "    benefit_file = genai.get_file(benefit_file.name)\n",
        "    fmla_file = genai.get_file(fmla_file.name)\n",
        "\n",
        "print(\"\\nFiles are ready.\")"
      ],
      "metadata": {
        "id": "KX1vn-MjpkkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Listing available models...\")\n",
        "for m in genai.list_models():\n",
        "    if \"generateContent\" in m.supported_generation_methods:\n",
        "        print(m.name)"
      ],
      "metadata": {
        "id": "g_M2BCL-qU1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Answer the question"
      ],
      "metadata": {
        "id": "tT9fuKd5rfnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Ask the Question\n",
        "# We pass the file objects DIRECTLY to the model.\n",
        "# This uses the 1-Million token context window (Long Context).\n",
        "model = genai.GenerativeModel(\"gemini-flash-latest\")\n",
        "\n",
        "response = model.generate_content(\n",
        "    [\n",
        "        \"You are an HR assistant. Answer based on these documents.\",\n",
        "        benefit_file,\n",
        "        fmla_file,\n",
        "        \"What is the deductible for Dental? Also, who approved John Smith's FMLA request?\"\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"\\n--- ANSWER ---\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "tB1pplUgpHOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Answer the question with sources\n",
        "\n",
        "\n",
        "**The Prompt (auditor_prompt):** how you ask is as important as what you ask. By demanding an \"Exact Quote\", you force the model to look at the pixels of the PDF text, which significantly reduces hallucinations.\n",
        "\n",
        "**The Validation:** This simple if/else block demonstrates the logic of a Guardrail. In a real FinTech app, if the model fails to output \"Source:\", the system would automatically flag the answer for human review rather than showing it to a customer."
      ],
      "metadata": {
        "id": "cjObdhjzric0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. DEFINE THE \"AUDITOR\" PROMPT\n",
        "# We don't just ask the question. We give strict instructions on HOW to answer.\n",
        "# This is \"System Prompting\" 101 for Finance.\n",
        "auditor_prompt = \"\"\"\n",
        "You are a strict Compliance Auditor for a bank.\n",
        "Your job is to answer the user's question using ONLY the provided documents.\n",
        "\n",
        "CRITICAL INSTRUCTION:\n",
        "For every claim you make, you must provide a \"Source Block\" in this exact format:\n",
        "[Source: Document Name | Page/Section | Exact Quote]\n",
        "\n",
        "Question:\n",
        "\"What is the deductible for Dental and Vision? Also, who approved John Smith's FMLA request?\"\n",
        "\"\"\"\n",
        "\n",
        "# 5. GENERATE CONTENT\n",
        "# Changing the model to gemini-flash-latest as gemini-1.5-flash was not found.\n",
        "model = genai.GenerativeModel(\"gemini-flash-latest\")\n",
        "\n",
        "print(\"\\nAnalyze documents...\")\n",
        "response = model.generate_content(\n",
        "    [auditor_prompt, benefit_file, fmla_file]\n",
        ")\n",
        "\n",
        "# 6. DISPLAY RESPONSE WITH VALIDATION\n",
        "print(\"-\" * 50)\n",
        "print(\"ü§ñ AI RESPONSE:\")\n",
        "print(\"-\" * 50)\n",
        "print(response.text)\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# 7. (OPTIONAL) VALIDATION CHECK\n",
        "# In a real app, you would parse the string \"[Source: ...]\" to build links.\n",
        "if \"Source:\" in response.text:\n",
        "    print(\"‚úÖ CITATION CHECK: PASSED\")\n",
        "    print(\"The model provided sources for verification.\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è CITATION CHECK: FAILED\")\n",
        "    print(\"Warning: The model did not cite its sources. Human review required.\")"
      ],
      "metadata": {
        "id": "4O8I2XJMrDK0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyND7o6s3EKMnsqcBq2TbN80",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RDGopal/IB9AU-2026/blob/main/SD3_GAN_Illustration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f625609d"
      },
      "source": [
        "## Generative Adversarial Networks (GANs)\n",
        "\n",
        "Generative Adversarial Networks (GANs) are a class of AI algorithms used in unsupervised machine learning, implemented by a system of two neural networks contesting with each other in a zero-sum game framework.\n",
        "\n",
        "### How GANs Work:\n",
        "\n",
        "GANs consist of two main components:\n",
        "1.  **Generator (G)**: This network learns to create new data instances that resemble the training data. It takes random noise as input and outputs synthetic data (e.g., images).\n",
        "2.  **Discriminator (D)**: This network learns to distinguish between real data (from the training set) and fake data (generated by the Generator). It acts as a binary classifier.\n",
        "\n",
        "The training process is adversarial:\n",
        "*   The Generator tries to fool the Discriminator by producing increasingly realistic fake data.\n",
        "*   The Discriminator tries to get better at identifying fake data.\n",
        "\n",
        "This continuous competition drives both networks to improve, resulting in a Generator that can produce highly realistic data.\n",
        "\n",
        "### GANs vs. VAEs (Variational Autoencoders)\n",
        "\n",
        "Both GANs and VAEs are generative models capable of creating new data, but they achieve this through different mechanisms and have distinct characteristics:\n",
        "\n",
        "| Feature           | GANs                                      | VAEs                                          |\n",
        "| :---------------- | :---------------------------------------- | :-------------------------------------------- |\n",
        "| **Architecture**  | Two competing networks: Generator & Discriminator | Encoder-Decoder architecture                  |\n",
        "| **Training**      | Adversarial (minimax game)                | Maximizes evidence lower bound (ELBO)         |\n",
        "| **Output Quality**| Can produce very sharp, realistic samples | Often produces blurrier samples               |\n",
        "| **Latent Space**  | Implicit, often unstructured              | Explicit, structured (Gaussian distribution)  |\n",
        "| **Sampling**      | Straightforward sampling from noise       | Sampling from the learned latent distribution |\n",
        "| **Control**       | Less direct control over generated features | More amenable to controlling features via latent space manipulation |\n",
        "| **Mode Collapse** | Prone to mode collapse (generating limited variety) | Less prone to mode collapse                 |\n",
        "\n",
        "In essence, GANs prioritize generating highly realistic samples by pitting two networks against each other, while VAEs focus on learning a structured and continuous latent representation of the data, which can be useful for tasks like interpolation and reconstruction, even if their generated samples are sometimes less sharp than those from GANs."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install torch torchvision matplotlib"
      ],
      "metadata": {
        "id": "kJI1Eez4sA9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5d88d9e0"
      },
      "source": [
        "### Hyperparameters and Data Loading\n",
        "\n",
        "This section initializes key parameters for the GAN and loads the MNIST dataset. The `latent_dim` is the size of the noise vector fed into the generator. `lr` is the learning rate for the optimizers, `batch_size` determines how many samples are processed at once, and `epochs` specifies the number of training cycles over the entire dataset. The MNIST dataset, consisting of handwritten digits, is loaded and transformed into tensors suitable for PyTorch models."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Hyperparameters\n",
        "latent_dim = 100\n",
        "lr = 0.0002\n",
        "batch_size = 64\n",
        "epochs = 5\n",
        "\n",
        "# MNIST Data Loader\n",
        "transform = transforms.ToTensor()\n",
        "dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "zT5cZ9MaUQkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aa33845"
      },
      "source": [
        "### Generator and Discriminator Network Architectures\n",
        "\n",
        "Here, we define the two core neural networks of the GAN:\n",
        "\n",
        "*   **Generator (`Generator`)**: This network takes a `latent_dim` (100 in this case) random noise vector as input and transforms it through several linear layers with `LeakyReLU` activations. The final layer uses `Tanh` to output pixel values in the range [-1, 1], which is common for image generation to match the possible range of normalized pixel values. The output is then reshaped to `(batch_size, 1, 28, 28)` to represent 28x28 grayscale images.\n",
        "\n",
        "*   **Discriminator (`Discriminator`)**: This network takes a flattened 28x28 image (784 pixels) as input. It uses linear layers with `LeakyReLU` activations and `Dropout` layers to prevent overfitting. The final layer uses `Sigmoid` activation to output a single probability score between 0 and 1, indicating whether the input image is real (closer to 1) or fake (closer to 0).\n",
        "\n",
        "After defining the networks, they are initialized and moved to the appropriate device (GPU if available, otherwise CPU). `BCELoss` (Binary Cross-Entropy Loss) is chosen as the loss function, and `Adam` optimizers are set up for both the Generator and Discriminator."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generator Network\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(512, 784),\n",
        "            nn.Tanh()  # Output in [-1,1], match MNIST [0,1] after denormalization\n",
        "        )\n",
        "    def forward(self, z):\n",
        "        return self.model(z).view(-1, 1, 28, 28)\n",
        "\n",
        "# Discriminator Network\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(784, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, img):\n",
        "        img_flat = img.view(-1, 784)\n",
        "        return self.model(img_flat)\n",
        "\n",
        "# Initialize Networks\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "G = Generator().to(device)\n",
        "D = Discriminator().to(device)\n",
        "\n",
        "# Loss and Optimizers\n",
        "criterion = nn.BCELoss()\n",
        "optimizer_G = optim.Adam(G.parameters(), lr=lr)\n",
        "optimizer_D = optim.Adam(D.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "ngDwlLs2Ue_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e51a189"
      },
      "source": [
        "### Training Loop\n",
        "\n",
        "This is the core training logic of the GAN, executed over a specified number of epochs. Within each epoch, the model iterates through the `dataloader` to get batches of real images. The training proceeds in two main phases for each batch:\n",
        "\n",
        "1.  **Train Discriminator**:\n",
        "    *   First, the Discriminator is updated to correctly classify real images as real and fake images (generated by the current Generator) as fake.\n",
        "    *   Random noise is fed to the Generator to create `fake_imgs`. Crucially, `.detach()` is used to prevent gradients from flowing back to the Generator during this phase, ensuring only the Discriminator learns.\n",
        "    *   The Discriminator's loss is calculated using `BCELoss` for both real and fake images, and the average is backpropagated to update its weights.\n",
        "\n",
        "2.  **Train Generator**:\n",
        "    *   Next, the Generator is updated to produce images that can fool the Discriminator.\n",
        "    *   New random noise is used to generate `fake_imgs`.\n",
        "    *   The Discriminator's output for these fake images is then compared against `real_labels` (ones). This \"tricks\" the Discriminator into classifying fake images as real, and the loss is backpropagated to update only the Generator's weights, making it generate more convincing fakes.\n",
        "\n",
        "The print statement after each epoch shows the current losses for both the Discriminator (D) and Generator (G), indicating their training progress."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KoaKcId2r8TG"
      },
      "outputs": [],
      "source": [
        "# Training Loop\n",
        "for epoch in range(epochs):\n",
        "    for i, (real_imgs, _) in enumerate(dataloader):\n",
        "        real_imgs = real_imgs.to(device)\n",
        "        batch_size = real_imgs.size(0)\n",
        "\n",
        "        # Train Discriminator\n",
        "        z = torch.randn(batch_size, latent_dim).to(device)\n",
        "        fake_imgs = G(z).detach()  # Detach to avoid training G here\n",
        "        real_labels = torch.ones(batch_size, 1).to(device)\n",
        "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
        "\n",
        "        outputs_real = D(real_imgs)\n",
        "        loss_real = criterion(outputs_real, real_labels)\n",
        "\n",
        "        outputs_fake = D(fake_imgs)\n",
        "        loss_fake = criterion(outputs_fake, fake_labels)\n",
        "\n",
        "        loss_D = (loss_real + loss_fake) / 2\n",
        "        optimizer_D.zero_grad()\n",
        "        loss_D.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # Train Generator\n",
        "        z = torch.randn(batch_size, latent_dim).to(device)\n",
        "        fake_imgs = G(z)\n",
        "        outputs = D(fake_imgs)\n",
        "        loss_G = criterion(outputs, real_labels)  # Trick D into thinking fake is real\n",
        "\n",
        "        optimizer_G.zero_grad()\n",
        "        loss_G.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}] | Loss D: {loss_D.item():.4f} | Loss G: {loss_G.item():.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c7d3514"
      },
      "source": [
        "### Generate and Visualize Samples\n",
        "\n",
        "After training, this section demonstrates the Generator's ability to create new images.\n",
        "\n",
        "*   A batch of 16 random noise vectors (`z`) is created.\n",
        "*   These vectors are fed into the trained Generator (`G`), which outputs 16 synthetic images.\n",
        "*   `.detach().cpu()` moves the generated images from the GPU (if used) to the CPU and detaches them from the computation graph, making them regular tensors suitable for visualization.\n",
        "*   Finally, `matplotlib` is used to display these 16 generated images in a 4x4 grid. Each image is desqueezed (removing the channel dimension) and shown in grayscale. This allows us to visually inspect the quality and diversity of the images the GAN has learned to produce."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate and Visualize Samples\n",
        "z = torch.randn(16, latent_dim).to(device)\n",
        "generated = G(z).detach().cpu()\n",
        "fig, axes = plt.subplots(4, 4, figsize=(8,8))\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(generated[i].squeeze(), cmap='gray')\n",
        "    ax.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CDYRoY2iUnut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Required Task 12\n",
        "Download the zip file `floorplans_v2-20251223T170650Z-3-001.zip` which contains a large sample of floorplan images. Your task is to train a GAN model based on these images. Train the model on the floorplan images and create code to generate new synthetic floorplans."
      ],
      "metadata": {
        "id": "3oi4D4NA-sqw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Optional Task\n",
        "The current Generative Adversarial Network (GAN) you've implemented is an unconditional GAN. This means it learns to generate images that resemble the training data (MNIST digits) but doesn't have a mechanism to control which digit it generates.\n",
        "\n",
        "To generate images for a chosen digit, like '7', you would need to implement a Conditional Generative Adversarial Network (CGAN). In a CGAN, the class label (e.g., the digit '7') is provided as an input to both the Generator and the Discriminator during training. This conditions the generation process on the desired output.\n",
        "\n",
        "Give it a shot - try to develop a CGAN!"
      ],
      "metadata": {
        "id": "IOG2tDuc0KFJ"
      }
    }
  ]
}
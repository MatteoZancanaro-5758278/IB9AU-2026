{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyPm3wKOMOyotSLc2Ze98A+y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RDGopal/IB9AU-2026/blob/main/MLM2_OCR_with_Gemini.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56e7b1d5"
      },
      "source": [
        "# Why Modern VLMs Excel for Real-World Receipts\n",
        "\n",
        "Modern Vision-Language Models (VLMs) like Google Gemini, GPT-4V, or Claude 3  are pre-trained on vast and diverse datasets encompassing both images and text, allowing them to develop a much broader understanding of visual and linguistic concepts. They can understand and reason about images and text in a more general, open-ended, and human-like way, rather than relying on rigid patterns learned from specific document types.\n",
        "\n",
        "The key advantages of using VLMs for real-world receipts include:\n",
        "\n",
        "1.  **Better Generalization**: VLMs are inherently more robust to variations in layout, font, language, and content. Their extensive pre-training enables them to process receipts from virtually any source without requiring explicit fine-tuning for each specific layout or design.\n",
        "2.  **Improved Handling of Noisy or Unstructured Data**: Unlike template-based OCR systems or models heavily reliant on learned document structures, VLMs can often make sense of incomplete, messy, or semi-structured data, inferring meaning from context and visual cues.\n",
        "3.  **Semantic Understanding**: VLMs move beyond mere character recognition or pattern matching. They understand the *semantics* of the information on a receipt. For instance, they can identify 'total amount' even if it's labeled differently (e.g., 'Grand Total', 'Amount Due', 'Sum') or placed in an unusual location, because they grasp the underlying financial concept.\n",
        "4.  **Zero-Shot/Few-Shot Learning**: With strong prompting, VLMs can often perform extraction tasks without any specific training examples for a given receipt type, or with very few examples, making them highly adaptable to new data streams.\n",
        "\n",
        "In essence, VLMs offer a flexible, intelligent, and scalable solution for the unpredictable nature of real-world financial documents, making them ideal for practical FinTech applications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7a5fa42"
      },
      "source": [
        "## Setup Gemini API Key\n",
        "\n",
        "#### Instructions\n",
        "1. Go to the Google AI Studio website (https://aistudio.google.com/app/apikey) to generate an API key. Make sure you are logged in with your Google account.\n",
        "2. Click 'Create API key in new project' or 'Get API Key' to generate a new key.\n",
        "3. Once generated, copy the API key.\n",
        "4. In Google Colab, click on the 'Secrets' tab (ðŸ”‘ icon on the left sidebar).\n",
        "5. Click 'Add new secret'.\n",
        "6. For the 'Name' field, type `GOOGLE_API_KEY`.\n",
        "7. For the 'Value' field, paste the API key you copied from Google AI Studio.\n",
        "8. Ensure the 'Notebook access' checkbox is enabled for this secret.\n",
        "9. In a new code cell, add the following Python code to load the API key from Colab secrets: `from google.colab import userdata` followed by `GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')`.\n",
        "10. Finally, set the environment variable for the Gemini API by running `os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cefecfb8"
      },
      "source": [
        "This code cell loads the API key from Colab secrets and sets it as an environment variable for the Gemini API."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "484360d3"
      },
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# Load the API key from Colab secrets, assuming it's stored as 'GEMINI_API_KEY'\n",
        "GOOGLE_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "\n",
        "# Set the environment variable for the Gemini API\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
        "\n",
        "print(\"API key loaded and environment variable set.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "357641f4"
      },
      "source": [
        "This code block imports the `google.generativeai` library and then lists all available Gemini models, filtering for those that support content generation. This helps identify which models can be used for tasks like receipt analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3824d1a"
      },
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "print(\"Listing available Gemini models:\")\n",
        "for m in genai.list_models():\n",
        "    if \"generateContent\" in m.supported_generation_methods:\n",
        "        print(f\"Name: {m.name}, Description: {m.description}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d602b4e3"
      },
      "source": [
        "This cell initializes the `gemini_pro_vision` model using the `gemini-2.5-flash` model, preparing it for image and text content generation tasks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9ba20bb"
      },
      "source": [
        "# Initialize the Gemini Pro Vision model with the updated name\n",
        "gemini_pro_vision = genai.GenerativeModel('gemini-2.5-flash')\n",
        "\n",
        "print(\"Google Gemini 2.5 Flash model initialized.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5466a784"
      },
      "source": [
        "This code loads an image from the specified path `/content/receipt1.jpg` into a PIL Image object and then displays it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "842baae8"
      },
      "source": [
        "from PIL import Image\n",
        "# Load the image from the specified path\n",
        "receipt_image_path = '/content/receipt1.jpg'\n",
        "receipt_image = Image.open(receipt_image_path)\n",
        "print(f\"Image '{receipt_image_path}' loaded successfully.\")\n",
        "display(receipt_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d30f01c8"
      },
      "source": [
        "This code block defines a detailed prompt for the Gemini VLM, instructing it to extract specific information from a receipt image into a structured JSON format. It then prepares the image and sends the request to the Gemini API, finally parsing and printing the structured response."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8071bdef"
      },
      "source": [
        "import io\n",
        "from PIL import Image\n",
        "import json # Import json at the top for clarity and consistency\n",
        "\n",
        "# Define a detailed prompt string for the Gemini VLM\n",
        "prompt = \"\"\"\n",
        "Analyze this receipt image and extract the following information in a structured JSON format.\n",
        "Ensure that all numerical values are returned as numbers (float or int), not strings.\n",
        "\n",
        "Extract:\n",
        "- \"store_name\": The name of the store.\n",
        "- \"date\": The date of the transaction in YYYY-MM-DD format.\n",
        "- \"time\": The time of the transaction in HH:MM format (24-hour).\n",
        "- \"items\": A list of individual items purchased. Each item should be an object with:\n",
        "    - \"description\": Name of the item.\n",
        "    - \"quantity\": Number of units purchased (integer).\n",
        "    - \"unit_price\": Price per unit (float).\n",
        "    - \"total_price\": Total price for that item (float).\n",
        "- \"subtotal\": The subtotal amount before tax (float).\n",
        "- \"tax\": The tax amount (float).\n",
        "- \"total_amount\": The final total amount paid (float).\n",
        "- \"currency\": The currency symbol or code (e.g., \"USD\", \"$\").\n",
        "\n",
        "If any information is not present, use null for its value.\n",
        "\n",
        "Example JSON structure:\n",
        "{\n",
        "  \"store_name\": \"Example Store\",\n",
        "  \"date\": \"2023-10-26\",\n",
        "  \"time\": \"14:30\",\n",
        "  \"items\": [\n",
        "    {\n",
        "      \"description\": \"Item A\",\n",
        "      \"quantity\": 1,\n",
        "      \"unit_price\": 10.50,\n",
        "      \"total_price\": 10.50\n",
        "    },\n",
        "    {\n",
        "      \"description\": \"Item B\",\n",
        "      \"quantity\": 2,\n",
        "      \"unit_price\": 5.25,\n",
        "      \"total_price\": 10.50\n",
        "    }\n",
        "  ],\n",
        "  \"subtotal\": 21.00,\n",
        "  \"tax\": 1.50,\n",
        "  \"total_amount\": 22.50,\n",
        "  \"currency\": \"$\"\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Convert receipt_image (which is an MPOImageFile) to JPEG bytes\n",
        "img_byte_arr = io.BytesIO()\n",
        "receipt_image.save(img_byte_arr, format='JPEG')\n",
        "img_byte_arr = img_byte_arr.getvalue()\n",
        "\n",
        "# 3. Create a content list containing the prompt and the converted image\n",
        "contents = [prompt, {\"mime_type\": \"image/jpeg\", \"data\": img_byte_arr}]\n",
        "\n",
        "# 4. Call the gemini_pro_vision.generate_content() method\n",
        "print(\"Sending request to Gemini Pro Vision model...\")\n",
        "response = gemini_pro_vision.generate_content(contents)\n",
        "\n",
        "# 5. Access the text part of the response\n",
        "response_text = response.text\n",
        "\n",
        "# 6. Print the raw text response\n",
        "print(\"\\n--- Raw Gemini Response ---\")\n",
        "print(response_text)\n",
        "print(\"---------------------------\")\n",
        "\n",
        "# 7. Attempt to parse the response.text as a JSON object\n",
        "try:\n",
        "    # Clean the response_text to remove markdown code block fences if present\n",
        "    if response_text.startswith('```json') and response_text.endswith('```'):\n",
        "        cleaned_response_text = response_text.lstrip('```json').rstrip('```').strip()\n",
        "    else:\n",
        "        cleaned_response_text = response_text.strip()\n",
        "\n",
        "    structured_data = json.loads(cleaned_response_text)\n",
        "    print(\"\\n--- Parsed Structured Data (JSON) ---\")\n",
        "    print(json.dumps(structured_data, indent=2))\n",
        "    print(\"-------------------------------------\")\n",
        "except json.JSONDecodeError as e:\n",
        "    print(f\"\\nError decoding JSON from Gemini output: {e}\")\n",
        "    print(\"Raw response could not be parsed as valid JSON. Check the output above for format issues.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcfca01a"
      },
      "source": [
        "This cell loads the `naver-clova-ix/cord-v2` dataset using the `datasets` library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7a381a4"
      },
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"naver-clova-ix/cord-v2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6adfd138"
      },
      "source": [
        "This cell displays the dataset object, showing its structure and the available splits (train, validation, test) along with their features and number of rows."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36ba8d7f"
      },
      "source": [
        "ds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94581c24"
      },
      "source": [
        "This code cell simply prints the total number of records available in the training split of the dataset, providing a quick overview of its size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2ef39f2"
      },
      "source": [
        "len(ds['train'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29a849bd"
      },
      "source": [
        "This cell converts the first 5 records of the training dataset into a Pandas DataFrame and displays it, allowing for a quick inspection of the data structure and content, including the image and ground truth JSON."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51f53cd0"
      },
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame(ds['train'][:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1c22628"
      },
      "source": [
        "This extensive code block is responsible for displaying the first 5 images and their corresponding ground truth data from the training set. It dynamically generates an HTML table with base64 encoded images and pretty-printed JSON ground truth for better visualization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "312ca5bf",
        "collapsed": true
      },
      "source": [
        "from IPython.display import display, HTML\n",
        "import pandas as pd\n",
        "import json\n",
        "import io\n",
        "import base64\n",
        "\n",
        "# Assuming the DataFrame with the first 5 rows is named 'df_first_5'\n",
        "# from the previous execution of cell NypN9z20Mm4E.\n",
        "# If not, let's re-create it here for clarity:\n",
        "df_first_5 = pd.DataFrame(ds['train'][:5])\n",
        "\n",
        "print(\"Displaying the first 5 images and their ground truth in a table:\")\n",
        "\n",
        "html_output = \"\"\"\n",
        "<style>\n",
        "  table {\n",
        "    border-collapse: collapse;\n",
        "    width: 100%;\n",
        "  }\n",
        "  th, td {\n",
        "    border: 1px solid #ddd;\n",
        "    padding: 8px;\n",
        "    text-align: left;\n",
        "    vertical-align: top;\n",
        "  }\n",
        "  th {\n",
        "    background-color: #f2f2f2;\n",
        "  }\n",
        "  img {\n",
        "    max-width: 300px; /* Limit image width */\n",
        "    height: auto;\n",
        "    display: block; /* Remove extra space below image */\n",
        "  }\n",
        "  pre {\n",
        "    white-space: pre-wrap; /* Preserve whitespace and wrap text */\n",
        "    word-wrap: break-word;\n",
        "  }\n",
        "</style>\n",
        "<table>\n",
        "  <tr>\n",
        "    <th>Image</th>\n",
        "    <th>Ground Truth</th>\n",
        "  </tr>\n",
        "\"\"\"\n",
        "\n",
        "for i, row in df_first_5.iterrows():\n",
        "    html_output += \"<tr>\"\n",
        "    # Image column\n",
        "    img_bytes = io.BytesIO()\n",
        "    row['image'].save(img_bytes, format='PNG') # Save the PIL image to bytes\n",
        "    img_base64 = base64.b64encode(img_bytes.getvalue()).decode('utf-8')\n",
        "    html_output += f\"<td><img src='data:image/png;base64,{img_base64}' width='200'></td>\"\n",
        "\n",
        "    # Ground Truth column\n",
        "    ground_truth_json = json.loads(row['ground_truth'])\n",
        "    html_output += f\"<td><pre>{json.dumps(ground_truth_json, indent=2)}</pre></td>\"\n",
        "    html_output += \"</tr>\"\n",
        "html_output += \"</table>\"\n",
        "\n",
        "display(HTML(html_output))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caf06fcb"
      },
      "source": [
        "This code block defines the process of extracting the image, store name, and overall total price for each receipt in `ds['train']`. It cleans the total price string to ensure it can be converted to a float and then creates a DataFrame named `df_receipt_summary` with the extracted information."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1c9e017d"
      },
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import re # Import regular expression module\n",
        "\n",
        "# Initialize an empty list to store the extracted data for each receipt\n",
        "receipt_data_df = []\n",
        "\n",
        "# Iterate through each record in ds['train']\n",
        "for record in ds['train']:\n",
        "    image = record['image']\n",
        "    ground_truth_str = record['ground_truth']\n",
        "\n",
        "    store_name = None\n",
        "    total_price = None\n",
        "\n",
        "    try:\n",
        "        ground_truth_json = json.loads(ground_truth_str)\n",
        "        gt_parse = ground_truth_json.get('gt_parse', {})\n",
        "\n",
        "        # 5. Extract the store_name\n",
        "        company_name = gt_parse.get('company', {}).get('name')\n",
        "        seller_name = gt_parse.get('seller', {}).get('name')\n",
        "\n",
        "        if company_name:\n",
        "            store_name = company_name\n",
        "        elif seller_name:\n",
        "            store_name = seller_name\n",
        "\n",
        "        # 6. Extract the total_price string\n",
        "        total_info = gt_parse.get('total', {})\n",
        "        total_price_str = total_info.get('total_price')\n",
        "\n",
        "        # 7. Clean and convert total_price to float\n",
        "        if total_price_str is not None and isinstance(total_price_str, str):\n",
        "            # Remove any non-digit, non-decimal characters (e.g., currency symbols, spaces, thousands separators)\n",
        "            # First, handle comma as decimal if present, convert to dot, then remove other non-digits except first dot\n",
        "            cleaned_price = total_price_str.replace(',', '.')\n",
        "\n",
        "            # If there are multiple dots (e.g., \"1.234.567.89\"), assume all but the last are thousands separators\n",
        "            # and consolidate them into a single decimal point or remove.\n",
        "            # A more robust way: keep digits and only one decimal point.\n",
        "            parts = re.findall(r'\\d+', cleaned_price) # Extract all number sequences\n",
        "            if parts:\n",
        "                numeric_string = ''.join(parts)\n",
        "                # Find the last potential decimal separator\n",
        "                last_dot_index = cleaned_price.rfind('.')\n",
        "                if last_dot_index != -1 and last_dot_index > cleaned_price.rfind(parts[-1]): # Check if it's actually a decimal after the last number\n",
        "                    # Reconstruct with the decimal point\n",
        "                    integer_part = ''.join(re.findall(r'\\d', cleaned_price[:last_dot_index]))\n",
        "                    decimal_part = ''.join(re.findall(r'\\d', cleaned_price[last_dot_index+1:]))\n",
        "                    cleaned_price = f\"{integer_part}.{decimal_part}\"\n",
        "                else:\n",
        "                    cleaned_price = numeric_string\n",
        "            else:\n",
        "                cleaned_price = \"\"\n",
        "\n",
        "            try:\n",
        "                if cleaned_price:\n",
        "                    total_price = float(cleaned_price)\n",
        "                else:\n",
        "                    total_price = None\n",
        "            except ValueError:\n",
        "                total_price = None # Conversion failed\n",
        "\n",
        "        # 8. Append extracted data to the list\n",
        "        receipt_data_df.append({\n",
        "            'image': image,\n",
        "            'store_name': store_name,\n",
        "            'total_price': total_price\n",
        "        })\n",
        "\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"Error decoding JSON for a record: {e}\")\n",
        "        continue # Skip to the next record if JSON is invalid\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred for a record: {e}\")\n",
        "        continue # Skip to the next record if an error occurs\n",
        "\n",
        "# Create the new DataFrame\n",
        "df_receipt_summary = pd.DataFrame(receipt_data_df)\n",
        "\n",
        "print(f\"Created df_receipt_summary with {len(df_receipt_summary)} records.\")\n",
        "print(\"First 5 rows of df_receipt_summary:\")\n",
        "display(df_receipt_summary.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81890204"
      },
      "source": [
        "This cell assigns the `df_receipt_summary` DataFrame (created in the previous data extraction step) to `df_receipt`, as per the task instructions. It then prints the number of records and displays the head of `df_receipt` to verify its content and structure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d209ddae"
      },
      "source": [
        "df_receipt = df_receipt_summary\n",
        "\n",
        "print(f\"Number of records in df_receipt: {len(df_receipt)}\")\n",
        "print(\"First 5 rows of df_receipt:\")\n",
        "display(df_receipt.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66609980"
      },
      "source": [
        "This cell calculates and prints the number of records in the `df_receipt` DataFrame where the 'store_name' column has a `None` value. This is useful for understanding the completeness of the extracted store name data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78d7d378"
      },
      "source": [
        "num_none_store_name = df_receipt['store_name'].isnull().sum()\n",
        "print(f\"Number of records with None in 'store_name': {num_none_store_name}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a2718b0"
      },
      "source": [
        "This cell removes the 'store_name' column from the `df_receipt` DataFrame, as it was found to be entirely `None`. It then displays the head of the DataFrame to confirm the column's removal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddf8e4c2",
        "collapsed": true
      },
      "source": [
        "df_receipt = df_receipt.drop(columns=['store_name'])\n",
        "print(\" 'store_name' column removed from df_receipt.\")\n",
        "print(\"First 5 rows of df_receipt after column removal:\")\n",
        "display(df_receipt.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aaf306b"
      },
      "source": [
        "#Required Task 10\n",
        "Your task is to utilize the Gemini VLM to predict the `total_price` for a subset of receipts and then evaluate the model's performance against the ground truth `total_price` already present in `df_receipt`.\n",
        "\n",
        "#### Instructions:\n",
        "\n",
        "1.  **Randomly Select 15 Records**:\n",
        "    *   From the `df_receipt` DataFrame, randomly select 100 receipts. This will be your test set for Gemini's prediction.\n",
        "    *   Store these 15 records in a new DataFrame, say `df_test_receipts`.\n",
        "\n",
        "2.  **Define a Prompt for Gemini**:\n",
        "    *   Create a clear and concise prompt that instructs Gemini to extract only the `total_price` from a given receipt image. Emphasize that the output should be a single numerical value (float).\n",
        "    *   Example prompt: `\"Extract the total amount from this receipt. Provide only the numerical value as a float.\"`\n",
        "\n",
        "3.  **Process `df_test_receipts` with Gemini**:\n",
        "    *   Iterate through each row in `df_test_receipts`.\n",
        "    *   For each receipt's image, call the Gemini VLM with your defined prompt.\n",
        "    *   Parse Gemini's response to extract the predicted `total_price`. Handle potential errors (e.g., non-numeric responses, API issues) by assigning `None` or `NaN` if a valid price cannot be extracted.\n",
        "    *   Add the extracted prediction as a new column, `predicted_total_price`, to `df_test_receipts`.\n",
        "\n",
        "4.  **Evaluate Predictions**:\n",
        "    *   Compare the `predicted_total_price` with the `total_price` (ground truth) in `df_test_receipts`.\n",
        "    *   Calculate appropriate evaluation metrics. Consider the following:\n",
        "        *   **Mean Absolute Error (MAE)**: Average of the absolute differences between predicted and actual values.\n",
        "        *   **Number of successful extractions**: Count how many predictions were successfully extracted (not `None` or `NaN`).\n",
        "        *   **Accuracy within a threshold**: Calculate the percentage of predictions that are within a certain percentage (e.g., 5% or 10%) of the ground truth.\n",
        "\n",
        "5.  **Display Results**:\n",
        "    *   Print the calculated evaluation metrics.\n",
        "    *   Display `df_test_receipts` with `total_price` and `predicted_total_price` columns for a few sample rows to show the comparison.\n"
      ]
    }
  ]
}